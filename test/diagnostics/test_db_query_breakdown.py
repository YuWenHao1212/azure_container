#!/usr/bin/env python
"""
è¨ºæ–·è…³æœ¬:è©³ç´°åˆ†è§£ Database Query çš„æ™‚é–“æ¶ˆè€—
ç›®çš„:ç†è§£ pgvector æŸ¥è©¢çš„å„å€‹éšæ®µè€—æ™‚
"""
import asyncio
import json
import logging
import sys
import time
from datetime import UTC, datetime
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DetailedTimeTracker:
    """è©³ç´°è¿½è¹¤å„éšæ®µæ™‚é–“çš„å·¥å…·"""

    def __init__(self):
        self.stages = []
        self.current_stage = None
        self.start_time = None

    def start(self, stage_name: str):
        """é–‹å§‹ä¸€å€‹éšæ®µ"""
        self.current_stage = stage_name
        self.start_time = time.perf_counter()
        return self

    def end(self) -> float:
        """çµæŸç•¶å‰éšæ®µä¸¦è¨˜éŒ„æ™‚é–“"""
        if self.start_time is None or self.current_stage is None:
            return 0
        elapsed = (time.perf_counter() - self.start_time) * 1000  # è½‰æ›ç‚º ms
        self.stages.append({
            "stage": self.current_stage,
            "duration_ms": round(elapsed, 2)
        })
        self.current_stage = None
        self.start_time = None
        return elapsed


async def analyze_single_db_query(skill_name: str, embedding: list[float], skill_category: str, connection_pool) -> dict:
    """åˆ†æå–®å€‹è³‡æ–™åº«æŸ¥è©¢çš„è©³ç´°æ™‚é–“"""
    from pgvector.asyncpg import register_vector

    tracker = DetailedTimeTracker()
    result = {
        "skill_name": skill_name,
        "skill_category": skill_category,
        "stages": []
    }

    try:
        # Stage 1: å¾é€£æ¥æ± ç²å–é€£æ¥
        tracker.start("acquire_connection")
        conn_context = connection_pool.acquire()
        conn = await conn_context.__aenter__()
        tracker.end()

        # Stage 2: pgvector å·²åœ¨é€£æ¥æ± åˆå§‹åŒ–æ™‚è¨»å†Š
        # ä¸éœ€è¦å†è¨»å†Š - çœä¸‹ 607ms!

        # Stage 3: æº–å‚™æŸ¥è©¢åƒæ•¸
        tracker.start("prepare_query")
        threshold = 0.30 if skill_category == "SKILL" else 0.25
        query = """
        WITH ranked_courses AS (
            SELECT
                course_type_standard,
                name,
                1 - (embedding <=> $1::vector) as similarity,
                CASE
                    WHEN $3 = 'SKILL' THEN
                        CASE course_type_standard
                            WHEN 'course' THEN 3
                            WHEN 'project' THEN 2
                            WHEN 'certification' THEN 1
                            ELSE 0
                        END
                    WHEN $3 = 'FIELD' THEN
                        CASE course_type_standard
                            WHEN 'specialization' THEN 3
                            WHEN 'degree' THEN 2
                            WHEN 'certification' THEN 1
                            ELSE 0
                        END
                    ELSE 0
                END as priority_score
            FROM courses
            WHERE platform = 'coursera'
            AND embedding IS NOT NULL
            AND 1 - (embedding <=> $1::vector) >= $2
            ORDER BY priority_score DESC, similarity DESC
            LIMIT 10
        )
        SELECT
            COUNT(*) > 0 as has_courses,
            COUNT(*) as total_count,
            SUM(CASE WHEN priority_score > 0 THEN 1 ELSE 0 END) as preferred_count,
            SUM(CASE WHEN priority_score = 0 THEN 1 ELSE 0 END) as other_count
        FROM ranked_courses;
        """
        tracker.end()

        # Stage 4: åŸ·è¡ŒæŸ¥è©¢(é€™æ˜¯ä¸»è¦è€—æ™‚)
        tracker.start("execute_query")
        query_result = await conn.fetchrow(query, embedding, threshold, skill_category)
        tracker.end()

        # Stage 5: è™•ç†æŸ¥è©¢çµæœ
        tracker.start("process_result")
        processed_result = {
            "has_courses": query_result["has_courses"],
            "count": min(query_result["total_count"], 10),
            "preferred_count": query_result.get("preferred_count", 0),
            "other_count": query_result.get("other_count", 0)
        }
        tracker.end()

        # Stage 6: é‡‹æ”¾é€£æ¥
        tracker.start("release_connection")
        await conn_context.__aexit__(None, None, None)
        tracker.end()

        # è¨˜éŒ„æ‰€æœ‰éšæ®µ
        result["stages"] = tracker.stages
        result["total_ms"] = sum(s["duration_ms"] for s in tracker.stages)
        result["query_result"] = processed_result
        result["success"] = True

    except Exception as e:
        logger.error(f"æŸ¥è©¢å¤±æ•— {skill_name}: {e}")
        result["error"] = str(e)
        result["success"] = False
        result["stages"] = tracker.stages

    return result


async def analyze_parallel_queries(num_queries: int = 6) -> dict:
    """åˆ†æä¸¦è¡ŒæŸ¥è©¢çš„æ™‚é–“åˆ†è§£"""
    import random
    import string

    from src.services.course_search_singleton import get_course_search_service
    from src.services.llm_factory import get_embedding_client

    logger.info("="*80)
    logger.info(f"ğŸ”¬ åˆ†æ {num_queries} å€‹ä¸¦è¡Œè³‡æ–™åº«æŸ¥è©¢")
    logger.info("="*80)

    # åˆå§‹åŒ–æœå‹™
    logger.info("\nğŸ“ åˆå§‹åŒ–æœå‹™...")
    service = await get_course_search_service()
    connection_pool = service._connection_pool
    embedding_client = get_embedding_client(api_name="course_search")

    # ç”Ÿæˆæ¸¬è©¦æŠ€èƒ½
    suffix = ''.join(random.choices(string.ascii_lowercase, k=4))
    test_skills = []
    for i in range(num_queries):
        if i % 2 == 0:
            skill = {
                "name": f"TestSkill_{suffix}_{i}",
                "category": "SKILL",
                "text": f"TestSkill_{suffix}_{i} course tutorial project certificate"
            }
        else:
            skill = {
                "name": f"TestField_{suffix}_{i}",
                "category": "FIELD",
                "text": f"TestField_{suffix}_{i} specialization degree track curriculum"
            }
        test_skills.append(skill)

    # ç”Ÿæˆ embeddings
    logger.info(f"\nğŸ“ ç”Ÿæˆ {num_queries} å€‹ embeddings...")
    start_time = time.perf_counter()
    texts = [s["text"] for s in test_skills]
    embeddings = await embedding_client.create_embeddings(texts)
    embedding_time = (time.perf_counter() - start_time) * 1000
    logger.info(f"âœ… Embedding å®Œæˆ:{embedding_time:.1f}ms")

    # åŸ·è¡Œä¸¦è¡ŒæŸ¥è©¢
    logger.info(f"\nğŸ“ åŸ·è¡Œ {num_queries} å€‹ä¸¦è¡ŒæŸ¥è©¢...")
    parallel_start = time.perf_counter()

    # å‰µå»ºæŸ¥è©¢ä»»å‹™
    tasks = []
    for skill, embedding in zip(test_skills, embeddings, strict=False):
        task = analyze_single_db_query(
            skill["name"],
            embedding,
            skill["category"],
            connection_pool
        )
        tasks.append(task)

    # ä¸¦è¡ŒåŸ·è¡Œ
    results = await asyncio.gather(*tasks)

    parallel_time = (time.perf_counter() - parallel_start) * 1000
    logger.info(f"âœ… ä¸¦è¡ŒæŸ¥è©¢å®Œæˆ:{parallel_time:.1f}ms")

    # åˆ†æçµæœ
    analysis = {
        "test_name": "Database Query Breakdown Analysis",
        "timestamp": datetime.now(UTC).isoformat(),
        "num_queries": num_queries,
        "embedding_time_ms": round(embedding_time, 2),
        "total_parallel_time_ms": round(parallel_time, 2),
        "queries": results,
        "stage_summary": {},
        "statistics": {}
    }

    # çµ±è¨ˆå„éšæ®µæ™‚é–“
    stage_times = {}
    for query_result in results:
        if query_result.get("success"):
            for stage in query_result.get("stages", []):
                stage_name = stage["stage"]
                if stage_name not in stage_times:
                    stage_times[stage_name] = []
                stage_times[stage_name].append(stage["duration_ms"])

    # è¨ˆç®—çµ±è¨ˆ
    for stage_name, times in stage_times.items():
        analysis["stage_summary"][stage_name] = {
            "avg_ms": round(sum(times) / len(times), 2),
            "min_ms": round(min(times), 2),
            "max_ms": round(max(times), 2),
            "total_ms": round(sum(times), 2),
            "count": len(times)
        }

    # è¨ˆç®—æ¯å€‹æŸ¥è©¢çš„å¹³å‡æ™‚é–“
    query_times = [r["total_ms"] for r in results if r.get("success")]
    if query_times:
        analysis["statistics"] = {
            "avg_query_time_ms": round(sum(query_times) / len(query_times), 2),
            "min_query_time_ms": round(min(query_times), 2),
            "max_query_time_ms": round(max(query_times), 2),
            "slowest_query": max(results, key=lambda x: x.get("total_ms", 0))["skill_name"],
            "fastest_query": min(results, key=lambda x: x.get("total_ms", float('inf')))["skill_name"]
        }

    return analysis


async def run_detailed_db_analysis():
    """åŸ·è¡Œè©³ç´°çš„è³‡æ–™åº«æŸ¥è©¢åˆ†æ"""

    # åŸ·è¡Œ 5 è¼ªæ¸¬è©¦
    all_analyses = []

    for round_num in range(5):
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ”„ ç¬¬ {round_num + 1}/5 è¼ªæ¸¬è©¦")
        logger.info(f"{'='*80}")

        analysis = await analyze_parallel_queries(6)
        all_analyses.append(analysis)

        # æ‰“å°ç°¡è¦çµæœ
        logger.info("\nğŸ“Š æœ¬è¼ªçµæœ:")
        logger.info(f"ç¸½ä¸¦è¡Œæ™‚é–“: {analysis['total_parallel_time_ms']:.1f}ms")
        logger.info(f"å¹³å‡å–®æŸ¥è©¢: {analysis['statistics']['avg_query_time_ms']:.1f}ms")

        logger.info("\nğŸ” éšæ®µåˆ†è§£(å¹³å‡):")
        for stage, stats in analysis["stage_summary"].items():
            percentage = (stats["avg_ms"] / analysis['statistics']['avg_query_time_ms']) * 100
            logger.info(f"   {stage}: {stats['avg_ms']:.1f}ms ({percentage:.1f}%)")

        # çŸ­æš«å»¶é²
        if round_num < 4:
            await asyncio.sleep(1)

    # ä¿å­˜è©³ç´°å ±å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"/Users/yuwenhao/Documents/GitHub/azure_container/test/logs/db_query_breakdown_{timestamp}.json"

    # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
    final_report = {
        "test_name": "Database Query Detailed Breakdown",
        "timestamp": datetime.now(UTC).isoformat(),
        "rounds": all_analyses,
        "overall_statistics": {}
    }

    # èšåˆæ‰€æœ‰è¼ªæ¬¡çš„éšæ®µçµ±è¨ˆ
    all_stage_times = {}
    for analysis in all_analyses:
        for stage, stats in analysis["stage_summary"].items():
            if stage not in all_stage_times:
                all_stage_times[stage] = []
            all_stage_times[stage].append(stats["avg_ms"])

    # è¨ˆç®—ç¸½é«”å¹³å‡
    for stage, times in all_stage_times.items():
        final_report["overall_statistics"][stage] = {
            "avg_ms": round(sum(times) / len(times), 2),
            "min_ms": round(min(times), 2),
            "max_ms": round(max(times), 2)
        }

    # è¨ˆç®—ç¸½é«”æŸ¥è©¢æ™‚é–“
    all_query_times = []
    for analysis in all_analyses:
        if "statistics" in analysis and "avg_query_time_ms" in analysis["statistics"]:
            all_query_times.append(analysis["statistics"]["avg_query_time_ms"])

    if all_query_times:
        final_report["overall_statistics"]["total_query"] = {
            "avg_ms": round(sum(all_query_times) / len(all_query_times), 2),
            "min_ms": round(min(all_query_times), 2),
            "max_ms": round(max(all_query_times), 2)
        }

    # ä¿å­˜å ±å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, indent=2, ensure_ascii=False)

    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š åˆ†æå®Œæˆ!")
    logger.info(f"ğŸ“ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    logger.info("="*80)

    # æ‰“å°æœ€çµ‚çµ±è¨ˆ
    logger.info("\nğŸ“ˆ ç¸½é«”çµ±è¨ˆ(5 è¼ªå¹³å‡):")
    if "total_query" in final_report["overall_statistics"]:
        logger.info(f"å¹³å‡æŸ¥è©¢æ™‚é–“: {final_report['overall_statistics']['total_query']['avg_ms']:.1f}ms")

    logger.info("\nğŸ” éšæ®µåˆ†è§£(ç¸½é«”å¹³å‡):")
    total_avg = final_report["overall_statistics"].get("total_query", {}).get("avg_ms", 0)
    for stage, stats in final_report["overall_statistics"].items():
        if stage != "total_query":
            percentage = (stats["avg_ms"] / total_avg * 100) if total_avg > 0 else 0
            logger.info(f"   {stage}: {stats['avg_ms']:.1f}ms ({percentage:.1f}%)")


if __name__ == "__main__":
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    from dotenv import load_dotenv
    load_dotenv()

    # åŸ·è¡Œåˆ†æ
    asyncio.run(run_detailed_db_analysis())
