# Resume Tailoring API æ·±åº¦åˆ†æå ±å‘Š

**æ–‡æª”ç‰ˆæœ¬**: 1.2.0  
**åˆ†ææ—¥æœŸ**: 2025-08-11  
**åˆ†æè€…**: Claude Code  
**API ç‰ˆæœ¬**: v2.1.0-simplified  
**æœ€å¾Œæ›´æ–°**: 2025-08-11 - æ–°å¢æ¥µç«¯æƒ…æ³è™•ç†ï¼ˆé—œéµå­—è¢«ç§»é™¤ï¼‰

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦

æœ¬å ±å‘Šç‚º `/api/v1/tailor-resume` API çš„æ·±åº¦æŠ€è¡“åˆ†æï¼Œæ¶µè“‹æ¶æ§‹è¨­è¨ˆã€è³‡æ–™æµç¨‹ã€å¯¦ä½œç´°ç¯€åŠæ•ˆèƒ½æŒ‡æ¨™ã€‚

## ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆï¼šå…©éšæ®µç®¡ç·šæ¶æ§‹

### Stage 1: Instruction Compiler (GPT-4.1 mini)
- **åŠŸèƒ½**ï¼šåˆ†æå±¥æ­·çµæ§‹ï¼Œç”Ÿæˆå„ªåŒ–æŒ‡ä»¤
- **è¼¸å‡º**ï¼šJSON æ ¼å¼çš„çµæ§‹åŒ–æŒ‡ä»¤
  - `resume_sections`: è­˜åˆ¥ç¾æœ‰ç« ç¯€
  - `section_metadata`: åŸºæœ¬çµ±è¨ˆè³‡æ–™
- **æ•ˆèƒ½**ï¼š~280ms åŸ·è¡Œæ™‚é–“
- **æˆæœ¬å„ªå‹¢**ï¼šä½¿ç”¨ GPT-4.1 mini (æ¯” GPT-4 ä¾¿å®œ 200x)

### Stage 2: Resume Writer (GPT-4.1)
- **åŠŸèƒ½**ï¼šåŸ·è¡ŒæŒ‡ä»¤ï¼Œå„ªåŒ–å±¥æ­·å…§å®¹
- **è¼¸å‡º**ï¼š
  - `optimized_resume`: å„ªåŒ–å¾Œçš„ HTML
  - `applied_improvements`: æ”¹é€²æ¸…å–®
- **æ•ˆèƒ½**ï¼š~2100ms åŸ·è¡Œæ™‚é–“
- **Prompt å„ªåŒ–**ï¼šç°¡åŒ– 47%ï¼ˆ717è¡Œâ†’380è¡Œï¼‰

## ğŸ“Š å®Œæ•´è³‡æ–™æµç¨‹

```
è«‹æ±‚è¼¸å…¥ â†’ é©—è­‰ â†’ Stage 1 ç·¨è­¯ â†’ Stage 2 åŸ·è¡Œ â†’ å¾Œè™•ç† â†’ å›æ‡‰
```

### 1. è«‹æ±‚è¼¸å…¥éšæ®µ

#### å¿…è¦åƒæ•¸
```typescript
interface TailorResumeRequest {
  job_description: string;      // â‰¥200 å­—å…ƒ
  original_resume: string;       // é è¨­ HTMLï¼Œä½†ä¹Ÿæ¥å— Plain Text, â‰¥200 å­—å…ƒ
  gap_analysis: {
    core_strengths: string[];    // 3-5 é …æ ¸å¿ƒå„ªå‹¢
    key_gaps: string[];         // 3-5 é …å·®è·ï¼ˆå«åˆ†é¡æ¨™è¨˜ï¼‰
    quick_improvements: string[]; // 3-5 é …å¿«é€Ÿæ”¹é€²
    covered_keywords?: string[]; // å·²è¦†è“‹é—œéµå­—
    missing_keywords?: string[]; // ç¼ºå¤±é—œéµå­—
    // å¿…å¡«æ¬„ä½ï¼šå¾å‰ç½® APIï¼ˆindex-calculation æˆ– gap-analysisï¼‰ç²å¾—
    coverage_percentage: number;  // é—œéµå­—è¦†è“‹ç‡ï¼ˆå¿…å¡«ï¼Œ0-100ï¼‰
    similarity_percentage: number; // ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”ï¼ˆå¿…å¡«ï¼Œ0-100ï¼‰
  };
  options?: {
    language: string;           // é è¨­: "English"
    include_visual_markers: boolean; // é è¨­: true
  };
}
```

### 2. é©—è­‰éšæ®µ

**è™•ç†æ–¹å¼ï¼šç´” Python ç¨‹å¼ç¢¼é©—è­‰ï¼ˆä¸ä½¿ç”¨ LLMï¼‰**

- **è¼¸å…¥é©—è­‰**ï¼ˆåœ¨ `_validate_inputs` æ–¹æ³•ä¸­ï¼‰ï¼š
  - é•·åº¦æª¢æŸ¥ï¼ˆæœ€å° 200 å­—å…ƒï¼‰
  - å¿…è¦æ¬„ä½æª¢æŸ¥
  - ç©ºç™½å­—ä¸²æª¢æŸ¥ï¼ˆä½¿ç”¨ `strip()`ï¼‰
  - **æ ¼å¼è™•ç†ç­–ç•¥**ï¼šä¸é©—è­‰ HTML æ ¼å¼ï¼Œå› ç‚º LLM å¯è™•ç† HTML å’Œ Plain Text
  
- **Gap Analysis æ­£è¦åŒ–**ï¼š
  - æ”¯æ´å¤šç¨®è¼¸å…¥æ ¼å¼ï¼ˆAPI æ ¼å¼ / ç›´æ¥æ ¼å¼ï¼‰
  - è‡ªå‹•è½‰æ›ç‚ºçµ±ä¸€æ ¼å¼
  - é©—è­‰åˆ†é¡æ¨™è¨˜å­˜åœ¨æ€§
  
  **ç¯„ä¾‹èªªæ˜**ï¼š
  ```python
  # API æ ¼å¼è¼¸å…¥ï¼ˆsnake_caseï¼‰
  {
    "core_strengths": ["Python expertise", "Team leadership"],
    "key_gaps": ["[Skill Gap] AWS experience", "[Presentation Gap] Quantified achievements"],
    "quick_improvements": ["Add metrics to achievements"],
    "coverage_percentage": 65,
    "similarity_percentage": 70
  }
  
  # ç›´æ¥æ ¼å¼è¼¸å…¥ï¼ˆPascalCaseï¼‰
  {
    "CoreStrengths": "Python expertise\nTeam leadership",
    "KeyGaps": "[Skill Gap] AWS experience\n[Presentation Gap] Quantified achievements",
    "QuickImprovements": "Add metrics to achievements"
  }
  
  # æ­£è¦åŒ–å¾Œçš„çµ±ä¸€æ ¼å¼
  {
    "CoreStrengths": "Python expertise\nTeam leadership",
    "KeyGaps": "[Skill Gap] AWS experience\n[Presentation Gap] Quantified achievements",
    "QuickImprovements": "Add metrics to achievements",
    "coverage_percentage": 65,  # ä¿ç•™åŸå§‹å€¼
    "similarity_percentage": 70  # ä¿ç•™åŸå§‹å€¼
  }
  ```

### 3. Stage 1 - Instruction Compilation

**é‡è¦ç™¼ç¾ï¼šInstructionCompiler å¯¦éš›ä¸Šåªåšçµæ§‹åˆ†æ**

æ ¹æ“š prompt æª¢æŸ¥ï¼ˆ`src/services/instruction_compiler.py` ç¬¬ 137-192 è¡Œï¼‰ï¼š
- Prompt ä¸­**åªä½¿ç”¨äº† `{resume_html}`**
- **æ²’æœ‰ä½¿ç”¨** `{key_gaps}` æˆ– `{quick_improvements}`
- é›–ç„¶ç¨‹å¼ç¢¼æº–å‚™äº†é€™äº›è®Šæ•¸ï¼Œä½† prompt template ä¸­æ²’æœ‰å¼•ç”¨

**å¯¦éš›åŠŸèƒ½**ï¼š
- è­˜åˆ¥å±¥æ­·ç« ç¯€ï¼ˆsummary, skills, experience ç­‰ï¼‰
- çµ±è¨ˆåŸºæœ¬è³‡è¨Šï¼ˆå·¥ä½œæ•¸é‡ã€æ•™è‚²æ•¸é‡ï¼‰
- åˆ¤æ–·æ˜¯å¦æœ‰é‡åŒ–æˆå°±
- ä¼°è¨ˆé æ•¸

```python
# ç›®å‰å¯¦ä½œï¼ˆå­˜åœ¨å‡—é¤˜åƒæ•¸ï¼‰
instructions = await instruction_compiler.compile_instructions(
    resume_html=original_resume,        # âœ… å”¯ä¸€çœŸæ­£ä½¿ç”¨çš„åƒæ•¸
    job_description=job_description,    # âŒ æœªä½¿ç”¨
    gap_analysis=gap_analysis_data,     # âŒ æœªä½¿ç”¨ï¼ˆé›–ç„¶æå–äº† KeyGaps å’Œ QuickImprovementsï¼‰
    covered_keywords=covered_keywords,  # âŒ æœªä½¿ç”¨
    missing_keywords=missing_keywords,  # âŒ æœªä½¿ç”¨
)

# å„ªåŒ–å»ºè­°ï¼šåªä¿ç•™å¿…è¦åƒæ•¸ï¼ˆâœ… å·²ç¢ºèªå¯è¡Œï¼‰
instructions = await instruction_compiler.compile_instructions(
    resume_html=original_resume  # åªéœ€è¦é€™å€‹
)
```

**è¼¸å‡ºçµæ§‹**ï¼š
```json
{
  "analysis": {
    "resume_sections": {
      "summary": "Professional Summary",
      "experience": "Work Experience",
      "skills": null,  // ä¸å­˜åœ¨çš„ç« ç¯€
      "education": "Education"
    },
    "section_metadata": {
      "total_sections": 3,
      "missing_critical": ["Skills"],
      "optimization_priority": ["summary", "experience"]
    }
  }
  // è¨»ï¼šç°¡åŒ–ç‰ˆæœ¬ç§»é™¤äº† instructions æ¬„ä½
  // çµæ§‹åˆ†æçµæœç›´æ¥å‚³éçµ¦ Stage 2 ä½œç‚ºåƒè€ƒ
}
```

### 4. Stage 2 - Resume Writing

**CSS æ¨™è¨˜è¦æ±‚**ï¼š
LLM åœ¨ v2.1.0-simplified prompt ä¸­è¢«æ˜ç¢ºè¦æ±‚åŠ å…¥ä»¥ä¸‹ CSS classesï¼š
- `opt-modified`: ä¿®æ”¹éçš„ç¾æœ‰å…§å®¹
- `opt-placeholder`: æ•¸é‡åŒ–ä½”ä½ç¬¦ï¼ˆå¦‚ [X%]ã€[TEAM SIZE]ï¼‰
- `opt-new`: æ–°å¢çš„å…§å®¹æˆ–ç« ç¯€

**Prompt çµæ§‹ï¼ˆv2.1.0-simplifiedï¼‰**ï¼š

- **ç³»çµ± Prompt**ï¼šå®šç¾©åŸ·è¡Œå¼•æ“è§’è‰²
- **ä½¿ç”¨è€… Prompt**ï¼šåŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡è³‡è¨Š
- **LLM é…ç½®**ï¼ˆå¾ v2.1.0-simplified.yaml å‹•æ…‹è¼‰å…¥ï¼‰ï¼š
  
  ```python
  # å¯¦éš›å€¼ä¾†è‡ª YAML æª”æ¡ˆ
  {
    "temperature": 0.3,      # å¾ yaml è¼‰å…¥ï¼ˆå·²æ›´æ–°ï¼‰
    "max_tokens": 6000,      # å¾ yaml è¼‰å…¥
    "top_p": 0.2,           # å¾ yaml è¼‰å…¥ï¼ˆå·²æ›´æ–°ï¼‰
    "seed": 42,             # å¾ yaml è¼‰å…¥
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0
  }
  ```

**åŸ·è¡ŒåŸå‰‡**ï¼š
- 90% åŸ·è¡Œï¼Œ10% åˆ†æ
- 100% Quick Improvements å¯¦æ–½ç‡
- çœŸå¯¦æ€§å„ªå…ˆï¼ˆä¸è™›æ§‹å…§å®¹ï¼‰

### 5. å¾Œè™•ç†éšæ®µï¼ˆæ··åˆæ–¹æ¡ˆå¢å¼·ï¼‰

#### 5.1 çµæœè§£æèˆ‡é—œéµå­—æ¨™è¨˜
```python
# JSON è§£æ
optimized_result = parse_llm_response(content)

# === æ–°å¢ï¼šé—œéµå­—æª¢æ¸¬èˆ‡æ¨™è¨˜ ===
# Step 1: æª¢æ¸¬å“ªäº› missing_keywords å¯¦éš›è¢«åŠ å…¥
actually_added_keywords = []
still_missing_keywords = []

if missing_keywords and optimized_html:
    found_missing, _ = self._detect_keywords_presence(
        optimized_html, missing_keywords
    )
    actually_added_keywords = found_missing
    still_missing_keywords = [
        kw for kw in missing_keywords 
        if kw not in found_missing
    ]

# Step 2: ä½¿ç”¨ EnhancedMarker ç²¾ç¢ºæ¨™è¨˜é—œéµå­—
if optimized_html and (covered_keywords or actually_added_keywords):
    from src.core.enhanced_marker import EnhancedMarker
    marker = EnhancedMarker()
    
    # covered_keywords â†’ opt-keyword-existingï¼ˆç¶ è‰²ï¼‰
    # actually_added_keywords â†’ opt-keywordï¼ˆè—è‰²ï¼‰
    optimized_html = marker.mark_keywords(
        html=optimized_html,
        original_keywords=covered_keywords or [],
        new_keywords=actually_added_keywords
    )

# Step 3: çµ±è¨ˆæ‰€æœ‰æ¨™è¨˜
from src.core.html_processor import HTMLProcessor
processor = HTMLProcessor()
marker_counts = processor.count_markers(optimized_html)

# HTML æ ¼å¼åŒ–
improvements_html = format_improvements_as_html(
    applied_improvements
)
```

#### 5.2 æŒ‡æ¨™è¨ˆç®—ï¼ˆå…§éƒ¨è™•ç†ç”¨ï¼Œéæœ€çµ‚è¼¸å‡ºï¼‰

**å®Œæ•´ç¯„ä¾‹**ï¼š
```python
# é€™æ˜¯å…§éƒ¨è™•ç†çš„è³‡æ–™çµæ§‹ï¼ˆåœ¨ _process_optimization_result_v2 ä¸­ï¼‰
final_result = {
    # ä¸»è¦å…§å®¹
    "optimized_resume": "<html>å„ªåŒ–å¾Œçš„å±¥æ­·...</html>",
    "applied_improvements": "<ul><li>Added metrics to achievements</li></ul>",
    "improvement_count": 5,
    "output_language": "English",
    
    # æ™‚é–“æŒ‡æ¨™
    "processing_time_ms": 4280,  # ç¸½è™•ç†æ™‚é–“
    "stage_timings": {
        "instruction_compilation_ms": 280,  # Stage 1 æ™‚é–“
        "resume_writing_ms": 2100          # Stage 2 æ™‚é–“
    },
    
    # åˆ†ææ´å¯Ÿ
    "gap_analysis_insights": {
        "structure_found": {
            "sections": {
                "summary": "Professional Summary",
                "experience": "Work Experience",
                "skills": null
            },
            "metadata": {
                "total_sections": 2,
                "missing_critical": ["Skills"]
            }
        },
        "improvements_applied": 5
    },
    
    # å…ƒæ•¸æ“š
    "metadata": {
        "version": "v2.1.0-simplified",
        "pipeline": "two-stage",
        "models": {
            "instruction_compiler": "gpt-4.1-mini",
            "resume_writer": "gpt-4.1"
        },
        "llm_processing_time_ms": 2380,
        "gap_analysis_external": true
    },
    
    # ç‹€æ…‹è³‡è¨Š
    "success": true,
    "message": "Resume optimized successfully with 5 improvements"
}

# é€™äº›å…§éƒ¨è³‡æ–™æœƒè¢«è½‰æ›ç‚º API å›æ‡‰æ ¼å¼ï¼ˆTailoringResponseï¼‰
    "gap_analysis_insights": {
        "structure_found": {...},
        "improvements_applied": count
    }
}
```

#### 5.3 å…ƒæ•¸æ“šè±å¯ŒåŒ–
```json
{
  "version": "v2.1.0-simplified",
  "pipeline": "two-stage",
  "models": {
    "instruction_compiler": "gpt-4.1-mini",
    "resume_writer": "gpt-4.1"
  },
  "gap_analysis_external": true,
  "llm_processing_time_ms": 2380
}
```

### 6. å›æ‡‰çµæ§‹

#### æˆåŠŸå›æ‡‰ï¼ˆç„¡è­¦å‘Šï¼‰
```json
{
  "success": true,
  "data": {
    "resume": "<html>å„ªåŒ–å¾Œçš„å±¥æ­·...</html>",
    "improvements": "<ul><li>æ”¹é€²1</li><li>æ”¹é€²2</li></ul>",
    "markers": {
      "keyword_new": 5,
      "keyword_existing": 8,
      "placeholder": 3,
      "new_section": 1,
      "modified": 12
    },
    "similarity": {
      "before": 65,
      "after": 85,
      "improvement": 20
    },
    "coverage": {
      "before": {
        "percentage": 60,
        "covered": ["Python", "SQL"],
        "missed": ["Docker", "AWS"]
      },
      "after": {
        "percentage": 90,
        "covered": ["Python", "SQL", "Docker", "AWS"],
        "missed": []
      },
      "improvement": 30,
      "newly_added": ["Docker", "AWS"]
    },
    "keyword_tracking": {
      "originally_covered": ["Python", "SQL"],
      "originally_missing": ["Docker", "AWS", "Redis"],
      "still_covered": ["Python", "SQL"],
      "removed": [],
      "newly_added": ["Docker", "AWS"],
      "still_missing": ["Redis"]
    }
  },
  "error": {
    "has_error": false,
    "code": "",
    "message": "",
    "details": "",
    "field_errors": {}
  },
  "warning": {
    "has_warning": false,
    "message": "",
    "details": []
  }
}
```

#### æˆåŠŸå›æ‡‰ï¼ˆæœ‰è­¦å‘Šï¼‰
```json
{
  "success": true,
  "data": {
    "resume": "<html>å„ªåŒ–å¾Œçš„å±¥æ­·...</html>",
    "keyword_tracking": {
      "originally_covered": ["Python", "Django", "PostgreSQL"],
      "removed": ["Python", "Django"],
      "warnings": ["2 keywords removed during optimization"]
    }
    // ... å…¶ä»–è³‡æ–™
  },
  "error": {
    "has_error": false,
    "code": "",
    "message": "",
    "details": "",
    "field_errors": {}
  },
  "warning": {
    "has_warning": true,
    "message": "Optimization successful but 2 keywords removed",
    "details": ["Python", "Django"]
  }
}
```

#### éŒ¯èª¤å›æ‡‰
```json
{
  "success": false,
  "data": null,
  "error": {
    "has_error": true,
    "code": "VALIDATION_TOO_SHORT",
    "message": "Resume content too short",
    "details": "Minimum 200 characters required",
    "field_errors": {
      "original_resume": ["Must be at least 200 characters"]
    }
  },
  "warning": {
    "has_warning": false,
    "message": "",
    "details": []
  }
}
```

## ğŸ¯ æ ¸å¿ƒè¨­è¨ˆç†å¿µ

### 1. 90/10 åŸ·è¡ŒåŸå‰‡
- **90% åŸ·è¡Œ**ï¼šå°ˆæ³¨æ–¼å¯¦æ–½é é©—è­‰çš„æ”¹é€²
- **10% åˆ†æ**ï¼šæœ€å°åŒ–é‡æ–°åˆ†æ
- **ä¾è³´å¤–éƒ¨æ™ºèƒ½**ï¼šGap Analysis æä¾›æ·±åº¦æ´å¯Ÿ

### 2. ä¸‰éšæ®µå„ªåŒ–å”è­°

#### Phase 1: Mandatory Quick Improvements
- 100% å¯¦æ–½ç‡è¦æ±‚
- ç²¾ç¢ºå®šä½ç›®æ¨™å…§å®¹
- è¿½è¹¤æ¯å€‹æ”¹è®Š

#### Phase 2: Gap Classification Handling
- **[Presentation Gap]** â†’ SURFACE æ“ä½œ
  - æ‰¾å‡ºéš±è—çš„è­‰æ“š
  - ä½¿å…¶æ˜é¡¯ä¸”çªå‡º
  
- **[Skill Gap]** â†’ BRIDGE æ“ä½œ
  - å°‹æ‰¾ç›¸é—œåŸºç¤ç¶“é©—
  - å»ºç«‹æŠ€èƒ½æ©‹æ¨‘

#### Phase 3: Structural Optimization
- å„ªåŒ–ç« ç¯€çµ„ç¹”
- ä¸è™›æ§‹æ–°å…§å®¹
- ä¿æŒçœŸå¯¦æ€§

### 3. CSS æ¨™è¨˜ç³»çµ±ï¼ˆæ··åˆæ–¹æ¡ˆå¯¦ä½œï¼‰

#### 3.1 æ¨™è¨˜é¡å‹èˆ‡è™•ç†ç­–ç•¥

**LLM ç”Ÿæˆçš„æ¨™è¨˜ï¼ˆStage 2ï¼‰**ï¼š
```css
.opt-modified {     /* ä¿®æ”¹çš„å…§å®¹ */
  /* ç”± LLM åœ¨å„ªåŒ–æ™‚ç›´æ¥ç”Ÿæˆ */
  /* æ¨™ç¤ºè¢«ä¿®æ”¹æˆ–å¢å¼·çš„ç¾æœ‰å…§å®¹ */
}
.opt-placeholder {  /* ä½”ä½ç¬¦ */
  /* å¦‚ [X%]ã€[TEAM SIZE]ã€[Y years] ç­‰ */
  /* æç¤ºç”¨æˆ¶éœ€è¦å¡«å…¥å…·é«”æ•¸å€¼ */
}
.opt-new {         /* æ–°å¢ç« ç¯€æˆ–å…§å®¹ */
  /* å…¨æ–°å‰µå»ºçš„å…§å®¹å€å¡Š */
  /* å¦‚æ–°å¢çš„ Summary æˆ– Skills ç« ç¯€ */
}
```

**Python å¾Œè™•ç†æ·»åŠ çš„æ¨™è¨˜ï¼ˆPost-processingï¼‰**ï¼š
```css
.opt-keyword {           /* æ–°å¢çš„é—œéµå­— */
  /* åŸæœ¬ç¼ºå°‘ä½†ç¾åœ¨æˆåŠŸåŠ å…¥çš„é—œéµå­— */
  /* ä¾†è‡ª missing_keywords ä¸”å¯¦éš›è¢«åŠ å…¥ */
  background-color: transparent;
  color: #6366f1;       /* ç´«è—è‰²ï¼Œè¡¨ç¤ºæ–°å¢ */
  border: 1px solid #c7d2fe;
  padding: 2px 4px;
  border-radius: 3px;
}
.opt-keyword-existing {  /* åŸæœ‰çš„é—œéµå­— */
  /* åŸæœ¬å°±å­˜åœ¨ä¸”èˆ‡è·ç¼ºåŒ¹é…çš„é—œéµå­— */
  /* ä¾†è‡ª covered_keywords */
  background-color: #2563eb;  /* æ·±è—è‰²èƒŒæ™¯ */
  color: white;               /* ç™½è‰²æ–‡å­— */
  padding: 3px 8px;
  border-radius: 3px;
}
```

#### 3.2 æ··åˆè™•ç†æ¶æ§‹

```mermaid
graph TD
    A[åŸå§‹å±¥æ­· + JD + Gap Analysis] --> B[Stage 1: Instruction Compiler]
    B --> C[Stage 2: Resume Writer<br/>LLM ç”Ÿæˆèªæ„æ¨™è¨˜]
    C --> D[å¾Œè™•ç†: é—œéµå­—æª¢æ¸¬<br/>åˆ¤æ–·å“ªäº› keywords å¯¦éš›è¢«åŠ å…¥]
    D --> E[å¾Œè™•ç†: EnhancedMarker<br/>ç²¾ç¢ºæ¨™è¨˜é—œéµå­—ä½ç½®]
    E --> F[HTMLProcessor<br/>çµ±è¨ˆæ‰€æœ‰æ¨™è¨˜]
    F --> G[è¿”å›å®Œæ•´çµæœ]
    
    style C fill:#fef3c7
    style D fill:#dbeafe
    style E fill:#dbeafe
```

#### 3.3 é—œéµå­—æª¢æ¸¬é‚è¼¯

**æ ¸å¿ƒå•é¡Œ**ï¼š`missing_keywords` â‰  `newly_added_keywords`

**å®Œæ•´çš„å››ç¨®é—œéµå­—ç‹€æ…‹**ï¼š
1. **åŸæœ¬å°±æœ‰ä¸”ä¿ç•™**ï¼ˆstill_coveredï¼‰â†’ `opt-keyword-existing`ï¼ˆç¶ è‰²ï¼‰
2. **åŸæœ¬å°±æœ‰ä½†è¢«ç§»é™¤**ï¼ˆremovedï¼‰â†’ âš ï¸ éœ€è¦è­¦å‘Šï¼
3. **åŸæœ¬æ²’æœ‰ä½†æˆåŠŸåŠ å…¥**ï¼ˆnewly_addedï¼‰â†’ `opt-keyword`ï¼ˆè—è‰²ï¼‰
4. **åŸæœ¬æ²’æœ‰ä¸”ä»ç„¶ç¼ºå°‘**ï¼ˆstill_missingï¼‰â†’ ä¸æ¨™è¨˜ï¼Œä½†è¨˜éŒ„åœ¨çµ±è¨ˆä¸­

**æª¢æ¸¬å¯¦ä½œ**ï¼š
```python
def _detect_keywords_presence(
    self, 
    html_content: str, 
    keywords_to_check: list[str]
) -> tuple[list[str], dict[str, list[int]]]:
    """
    æª¢æ¸¬ HTML å…§å®¹ä¸­å“ªäº›é—œéµå­—å¯¦éš›å­˜åœ¨
    
    æ™ºèƒ½åŒ¹é…è™•ç†ï¼š
    - "CI/CD" å¯åŒ¹é… "CI-CD", "CI CD", "CICD"
    - "Node.js" å¯åŒ¹é… "NodeJS", "nodejs"
    - "Machine Learning" å¯åŒ¹é… "ML"
    """
    from bs4 import BeautifulSoup
    import re
    
    # æå–ç´”æ–‡å­—å…§å®¹
    soup = BeautifulSoup(html_content, 'html.parser')
    text_content = soup.get_text(separator=' ', strip=True)
    
    found_keywords = []
    for keyword in keywords_to_check:
        # å»ºç«‹å¤šç¨®è®Šé«”æ¨¡å¼
        patterns = self._create_keyword_patterns(keyword)
        for pattern in patterns:
            if re.search(pattern, text_content, re.IGNORECASE):
                found_keywords.append(keyword)
                break
                
    return found_keywords
```

#### 3.4 å¯¦ä½œæ­¥é©Ÿ

**Step 1: ä¿®æ”¹ `_process_optimization_result_v2`**
```python
async def _process_optimization_result_v2(
    self,
    optimized_result: dict[str, Any],
    original_resume: str,
    output_language: str,
    stage_timings: dict[str, int],
    instructions: dict[str, Any],
    covered_keywords: list[str] = None,  # æ–°å¢åƒæ•¸
    missing_keywords: list[str] = None,  # æ–°å¢åƒæ•¸
) -> dict[str, Any]:
    """
    è™•ç†å„ªåŒ–çµæœä¸¦åŠ å…¥é—œéµå­—æ¨™è¨˜
    
    æ–°å¢åŠŸèƒ½ï¼š
    1. æª¢æ¸¬å“ªäº› missing_keywords å¯¦éš›è¢«åŠ å…¥
    2. ä½¿ç”¨ EnhancedMarker ç²¾ç¢ºæ¨™è¨˜é—œéµå­—
    3. çµ±è¨ˆæ‰€æœ‰æ¨™è¨˜é¡å‹
    """
    optimized_html = optimized_result.get("optimized_resume", "")
    
    # æª¢æ¸¬å¯¦éš›åŠ å…¥çš„é—œéµå­—
    actually_added_keywords = []
    if missing_keywords and optimized_html:
        found_missing, _ = self._detect_keywords_presence(
            optimized_html, missing_keywords
        )
        actually_added_keywords = found_missing
    
    # ä½¿ç”¨ EnhancedMarker æ¨™è¨˜é—œéµå­—
    if optimized_html and (covered_keywords or actually_added_keywords):
        from src.core.enhanced_marker import EnhancedMarker
        marker = EnhancedMarker()
        optimized_html = marker.mark_keywords(
            html=optimized_html,
            original_keywords=covered_keywords or [],
            new_keywords=actually_added_keywords
        )
    
    # çµ±è¨ˆæ‰€æœ‰æ¨™è¨˜
    from src.core.html_processor import HTMLProcessor
    processor = HTMLProcessor()
    marker_counts = processor.count_markers(optimized_html)
```

**Step 2: æ›´æ–° `tailor_resume` æ–¹æ³•èª¿ç”¨**
```python
# å‚³éé—œéµå­—åƒæ•¸åˆ°å¾Œè™•ç†
final_result = await self._process_optimization_result_v2(
    optimized_result,
    original_resume,
    output_language,
    stage_timings,
    instructions,
    covered_keywords=covered_keywords,  # æ–°å¢
    missing_keywords=missing_keywords,   # æ–°å¢
)
```

**Step 3: æ›´æ–° API å›æ‡‰çµæ§‹**
```python
# åœ¨ TailoringResponse ä¸­åŒ…å«è©³ç´°çš„é—œéµå­—è¿½è¹¤
"keyword_tracking": {
    "originally_covered": ["Python", "Django"],
    "originally_missing": ["Docker", "AWS", "Redis"],
    "actually_added": ["Docker", "AWS"],
    "still_missing": ["Redis"],
    "marker_counts": {
        "keyword": 2,
        "keyword-existing": 2,
        "modified": 10,
        "placeholder": 3,
        "new": 1
    }
}
```

#### 3.5 æ¥µç«¯æƒ…æ³è™•ç†ï¼šé—œéµå­—è¢«ç§»é™¤

**å•é¡Œå ´æ™¯**ï¼š
```python
# åŸå§‹å±¥æ­·
"5 years of Python and Django experience in web development"

# LLM å„ªåŒ–å¾Œï¼ˆå¯èƒ½é‡å¯«æ•´å€‹æ®µè½ï¼‰
"Half a decade of full-stack development expertise building scalable applications"

# å•é¡Œï¼šPython å’Œ Django é€™å…©å€‹ covered_keywords æ¶ˆå¤±äº†ï¼
```

**å®Œæ•´çš„é—œéµå­—åˆ†é¡å¯¦ä½œ**ï¼š
```python
def _categorize_keywords(
    self,
    optimized_html: str,
    covered_keywords: list[str],
    missing_keywords: list[str]
) -> dict[str, list[str]]:
    """
    åˆ†é¡æ‰€æœ‰é—œéµå­—çš„ç‹€æ…‹è®ŠåŒ–
    
    Returns:
        {
            "still_covered": [],      # åŸæœ‰ä¸”ä¿ç•™ï¼ˆç¶ è‰²æ¨™è¨˜ï¼‰
            "removed": [],            # åŸæœ‰ä½†è¢«ç§»é™¤ï¼ˆéœ€è¦è­¦å‘Šï¼ï¼‰
            "newly_added": [],        # æ–°å¢æˆåŠŸï¼ˆè—è‰²æ¨™è¨˜ï¼‰
            "still_missing": []       # ä»ç„¶ç¼ºå°‘ï¼ˆä¸æ¨™è¨˜ï¼‰
        }
    """
    # æª¢æ¸¬å„ªåŒ–å¾Œå±¥æ­·ä¸­çš„æ‰€æœ‰é—œéµå­—
    all_keywords = (covered_keywords or []) + (missing_keywords or [])
    present_keywords, _ = self._detect_keywords_presence(
        optimized_html, all_keywords
    )
    
    # åˆ†é¡
    result = {
        # åŸæœ¬å°±æœ‰çš„é—œéµå­—
        "still_covered": [
            kw for kw in (covered_keywords or []) 
            if kw in present_keywords
        ],
        "removed": [
            kw for kw in (covered_keywords or []) 
            if kw not in present_keywords
        ],
        
        # åŸæœ¬ç¼ºå°‘çš„é—œéµå­—
        "newly_added": [
            kw for kw in (missing_keywords or []) 
            if kw in present_keywords
        ],
        "still_missing": [
            kw for kw in (missing_keywords or []) 
            if kw not in present_keywords
        ]
    }
    
    # è­¦å‘Šï¼šå¦‚æœæœ‰é—œéµå­—è¢«ç§»é™¤
    if result["removed"]:
        logger.warning(
            f"âš ï¸ Keywords removed during optimization: {result['removed']}"
        )
    
    return result
```

**å¢å¼·çš„è™•ç†é‚è¼¯**ï¼š
```python
async def _process_optimization_result_v2(
    self,
    optimized_result: dict[str, Any],
    # ... å…¶ä»–åƒæ•¸
) -> dict[str, Any]:
    
    # å®Œæ•´çš„é—œéµå­—ç‹€æ…‹åˆ†é¡
    keyword_status = self._categorize_keywords(
        optimized_html,
        covered_keywords,
        missing_keywords
    )
    
    # ä½¿ç”¨ EnhancedMarker åªæ¨™è¨˜å­˜åœ¨çš„é—œéµå­—
    if optimized_html:
        from src.core.enhanced_marker import EnhancedMarker
        marker = EnhancedMarker()
        
        optimized_html = marker.mark_keywords(
            html=optimized_html,
            original_keywords=keyword_status["still_covered"],
            new_keywords=keyword_status["newly_added"]
        )
    
    # è¨ˆç®—è¦†è“‹ç‡è®ŠåŒ–
    original_coverage = len(covered_keywords or [])
    current_coverage = len(keyword_status["still_covered"]) + len(keyword_status["newly_added"])
    
    # å¦‚æœè¦†è“‹ç‡ä¸‹é™ï¼Œè¨˜éŒ„è­¦å‘Š
    if current_coverage < original_coverage:
        logger.warning(
            f"Coverage decreased: {original_coverage} â†’ {current_coverage} "
            f"({len(keyword_status['removed'])} keywords removed)"
        )
```

**å¢å¼·çš„ API å›æ‡‰çµæ§‹**ï¼š
```json
{
  "keyword_tracking": {
    "originally_covered": ["Python", "Django", "PostgreSQL"],
    "originally_missing": ["Docker", "AWS", "Redis"],
    
    // å„ªåŒ–å¾Œçš„ç‹€æ…‹
    "still_covered": ["PostgreSQL"],        // ä¿ç•™çš„ï¼ˆç¶ è‰²ï¼‰
    "removed": ["Python", "Django"],        // âš ï¸ è¢«ç§»é™¤çš„
    "newly_added": ["Docker", "AWS"],       // æ–°å¢çš„ï¼ˆè—è‰²ï¼‰
    "still_missing": ["Redis"],             // ä»ç¼ºå°‘çš„
    
    // çµ±è¨ˆèˆ‡è­¦å‘Š
    "coverage_change": {
      "before": 3,
      "after": 3,  // 1 ä¿ç•™ + 2 æ–°å¢
      "delta": 0,
      "removed_count": 2,
      "added_count": 2
    },
    "warnings": [
      "Keywords removed: Python, Django"
    ]
  }
}
```

**é é˜²ç­–ç•¥**ï¼š
1. åœ¨ LLM prompt ä¸­å¼·èª¿ä¿ç•™ covered_keywords
2. å¾Œè™•ç†æª¢æ¸¬ä¸¦è¨˜éŒ„è­¦å‘Š
3. æä¾›å“è³ªæŒ‡æ¨™ä¾›ç›£æ§

**API å›æ‡‰è¡Œç‚º**ï¼š
- HTTP ç‹€æ…‹ç¢¼ï¼š**200 OK**ï¼ˆå³ä½¿æœ‰é—œéµå­—è¢«ç§»é™¤ï¼‰
- `success`: `true`ï¼ˆå„ªåŒ–æœ¬èº«æˆåŠŸå®Œæˆï¼‰
- `warnings` é™£åˆ—ï¼šåŒ…å«è¢«ç§»é™¤é—œéµå­—çš„è­¦å‘Šè¨Šæ¯
- ç†ç”±ï¼šé—œéµå­—è¢«ç§»é™¤æ˜¯å„ªåŒ–çš„å‰¯ä½œç”¨ï¼Œä¸æ˜¯éŒ¯èª¤

## ğŸ“ˆ æ•ˆèƒ½æŒ‡æ¨™

### å›æ‡‰æ™‚é–“åˆ†æ
| æŒ‡æ¨™ | æ•¸å€¼ | ç›®æ¨™ | ç‹€æ…‹ |
|------|------|------|------|
| P50 | 4.28s | < 4.5s | âœ… |
| P95 | 7.00s | < 7.5s | âœ… |
| P99 | 7.00s | < 8.0s | âœ… |
| å¹³å‡ | 4.63s | - | - |

### éšæ®µè€—æ™‚åˆ†å¸ƒ
| éšæ®µ | P50 æ™‚é–“ | ä½”æ¯” | æ¨¡å‹ |
|------|----------|------|------|
| Instruction Compiler | 0.28s | 6.5% | GPT-4.1 mini |
| Resume Writer | 2.10s | 49.1% | GPT-4.1 |
| å¾Œè™•ç† | 0.05s | 1.2% | - |

### Token ä½¿ç”¨å„ªåŒ–
| ç‰ˆæœ¬ | Prompt Tokens | ç¸½ Tokens | æˆæœ¬ |
|------|---------------|-----------|------|
| v2.0.0 | ~4500 | 9000 | $0.304 |
| v2.1.0 | ~2520 | 7000 | $0.238 |
| ç¯€çœ | 44% | 22% | 22% |

## ğŸ”§ æŠ€è¡“å¯¦ä½œç´°ç¯€

### æœå‹™ä¾è³´é—œä¿‚
```
ResumeTailoringService
â”œâ”€â”€ LLMFactory (get_llm_client)
â”œâ”€â”€ InstructionCompiler
â”œâ”€â”€ UnifiedPromptService
â”œâ”€â”€ HTMLProcessor
â”œâ”€â”€ LanguageHandler
â”œâ”€â”€ MonitoringService
â””â”€â”€ å„èªè¨€ Standardizer
```

### é—œéµè¨­è¨ˆæ¨¡å¼
1. **Factory Pattern**: LLM å®¢æˆ¶ç«¯ç®¡ç†
2. **Strategy Pattern**: èªè¨€è™•ç†ç­–ç•¥
3. **Pipeline Pattern**: å¤šéšæ®µè™•ç†
4. **Template Pattern**: Prompt ç®¡ç†

### éŒ¯èª¤è™•ç†ç­–ç•¥ï¼ˆéµå¾ª FastAPI éŒ¯èª¤ç¢¼æ¨™æº–ï¼‰

#### éŒ¯èª¤å›æ‡‰æ ¼å¼ï¼ˆæ¨™æº–ç‰ˆï¼‰

æ¡ç”¨å®Œæ•´çš„ FastAPI æ¨™æº–æ ¼å¼ï¼ŒåŒ…å« `has_error` æ¬„ä½å’Œ `field_errors` æ”¯æ´ï¼š

```json
{
  "success": false,
  "data": null,
  "error": {
    "has_error": true,
    "code": "VALIDATION_TOO_SHORT",
    "message": "Resume content too short",
    "details": "Minimum 200 characters required",
    "field_errors": {
      "original_resume": ["Must be at least 200 characters"]
    }
  },
  "warning": {
    "has_warning": false,
    "message": "",
    "details": []
  }
}
```

#### éŒ¯èª¤ç¢¼åˆ†é¡èˆ‡ä½¿ç”¨

| éŒ¯èª¤é¡å‹ | éŒ¯èª¤ç¢¼ | HTTP | ä½¿ç”¨å ´æ™¯ |
|----------|--------|------|----------|
| **é©—è­‰éŒ¯èª¤ï¼ˆVALIDATION_*ï¼‰** | | | |
| æ–‡å­—å¤ªçŸ­ | `VALIDATION_TOO_SHORT` | 422 | å±¥æ­·æˆ–JD < 200å­—å…ƒ |
| å¿…å¡«æ¬„ä½ç¼ºå¤± | `VALIDATION_REQUIRED_FIELD` | 422 | ç¼ºå°‘ coverage_percentage ç­‰ |
| æ ¼å¼éŒ¯èª¤ | `VALIDATION_INVALID_FORMAT` | 422 | Gap Analysis æ ¼å¼ä¸æ­£ç¢º |
| **å¤–éƒ¨æœå‹™éŒ¯èª¤ï¼ˆEXTERNAL_*ï¼‰** | | | |
| é€Ÿç‡é™åˆ¶ | `EXTERNAL_RATE_LIMIT_EXCEEDED` | 429 | Azure OpenAI é€Ÿç‡é™åˆ¶ |
| æœå‹™éŒ¯èª¤ | `EXTERNAL_SERVICE_ERROR` | 502 | LLM å›æ‡‰æ ¼å¼éŒ¯èª¤æˆ–APIé…ç½®éŒ¯èª¤ |
| è¶…æ™‚ | `EXTERNAL_SERVICE_TIMEOUT` | 504 | LLM è™•ç†è¶…æ™‚ |
| **ç³»çµ±éŒ¯èª¤ï¼ˆSYSTEM_*ï¼‰** | | | |
| å…§éƒ¨éŒ¯èª¤ | `SYSTEM_INTERNAL_ERROR` | 500 | æœªé æœŸçš„ç¨‹å¼éŒ¯èª¤ |

#### è­¦å‘Šè™•ç†ç­–ç•¥

æ¡ç”¨é›™å±¤è­¦å‘Šæ©Ÿåˆ¶ï¼š
1. **æ¨™æº– warning æ¬„ä½**ï¼šæä¾›ä¸»è¦è­¦å‘Šè¨Šæ¯
2. **keyword_tracking.warnings**ï¼šæä¾›è©³ç´°çš„é—œéµå­—ç›¸é—œè­¦å‘Š

##### æˆåŠŸä½†æœ‰è­¦å‘Šçš„å›æ‡‰ç¯„ä¾‹

```json
{
  "success": true,
  "data": {
    "optimized_resume": "<html>...</html>",
    "keyword_tracking": {
      "originally_covered": ["Python", "Django", "PostgreSQL"],
      "removed": ["Python", "Django"],
      "newly_added": ["Docker", "AWS"],
      "still_missing": ["Redis"],
      "warnings": ["2 keywords removed during optimization: Python, Django"]
    }
    // ... å…¶ä»–è³‡æ–™
  },
  "error": {
    "has_error": false,
    "code": "",
    "message": "",
    "details": "",
    "field_errors": {}
  },
  "warning": {
    "has_warning": true,
    "message": "Optimization successful but 2 keywords removed",
    "details": ["Python", "Django"]
  }
}
```

**é‡è¦åŸå‰‡**ï¼š
- é—œéµå­—è¢«ç§»é™¤æ™‚ä»è¿”å› **HTTP 200**ï¼ˆæˆåŠŸï¼‰
- ä½¿ç”¨ `warning` æ¬„ä½è€Œé `error`
- å„ªåŒ–æœ¬èº«æˆåŠŸå®Œæˆï¼Œé—œéµå­—ç§»é™¤æ˜¯å‰¯ä½œç”¨è€ŒééŒ¯èª¤

#### å¯¦ä½œç¯„ä¾‹

```python
# æ ¹æ“š FASTAPI_ERROR_CODES_STANDARD.md
try:
    # ä¸»è¦é‚è¼¯
    result = await tailoring_service.tailor_resume(...)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é—œéµå­—è¢«ç§»é™¤ï¼ˆè­¦å‘Šä½†ä¸æ˜¯éŒ¯èª¤ï¼‰
    if result.get("keyword_tracking", {}).get("removed"):
        removed_keywords = result['keyword_tracking']['removed']
        result["warning"] = {
            "has_warning": True,
            "message": f"Optimization successful but {len(removed_keywords)} keywords removed",
            "details": removed_keywords
        }
    else:
        result["warning"] = {
            "has_warning": False,
            "message": "",
            "details": []
        }
    
    return TailoringResponse(
        success=True,
        data=result,
        error={
            "has_error": False,
            "code": "",
            "message": "",
            "details": "",
            "field_errors": {}
        },
        warning=result.get("warning")
    )
    
except ValueError as e:
    # é©—è­‰éŒ¯èª¤ - HTTP 422
    if "too short" in str(e).lower():
        error_code = "VALIDATION_TOO_SHORT"
        field_errors = {"original_resume": ["Must be at least 200 characters"]}
    elif "required" in str(e).lower():
        error_code = "VALIDATION_REQUIRED_FIELD"
        field_errors = {"gap_analysis": ["Missing required field"]}
    else:
        error_code = "VALIDATION_INVALID_FORMAT"
        field_errors = {}
    
    return TailoringResponse(
        success=False,
        data=None,
        error={
            "has_error": True,
            "code": error_code,
            "message": str(e),
            "details": "Please check your input data",
            "field_errors": field_errors
        },
        warning={
            "has_warning": False,
            "message": "",
            "details": []
        }
    )
    
except HTTPException as e:
    # HTTP ç•°å¸¸è™•ç†
    if e.status_code == 429:
        error_code = "EXTERNAL_RATE_LIMIT_EXCEEDED"
        message = "AI service rate limit exceeded, please retry after 60 seconds"
    elif e.status_code == 502:
        error_code = "EXTERNAL_SERVICE_ERROR"
        message = "AI service error, please try again"
    elif e.status_code == 504:
        error_code = "EXTERNAL_SERVICE_TIMEOUT"
        message = "AI processing timeout, please retry"
    else:
        error_code = "SYSTEM_INTERNAL_ERROR"
        message = "Service temporarily unavailable"
    
    return TailoringResponse(
        success=False,
        data=None,
        error={
            "has_error": True,
            "code": error_code,
            "message": message,
            "details": e.detail if settings.DEBUG else "",
            "field_errors": {}
        },
        warning={
            "has_warning": False,
            "message": "",
            "details": []
        }
    )
    
except Exception as e:
    # æœªé æœŸéŒ¯èª¤ - HTTP 500
    logger.error(f"Resume tailoring failed: {e}", exc_info=True)
    return TailoringResponse(
        success=False,
        data=None,
        error={
            "has_error": True,
            "code": "SYSTEM_INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": str(e) if settings.DEBUG else "Please try again later",
            "field_errors": {}
        },
        warning={
            "has_warning": False,
            "message": "",
            "details": []
        }
    )
```
## ğŸ›¡ï¸ å®‰å…¨è€ƒé‡

1. **è¼¸å…¥é©—è­‰**
   - é•·åº¦é™åˆ¶ï¼ˆ50-50000 å­—å…ƒï¼‰ 
   - HTML æ¸…ç†èˆ‡é©—è­‰
   - é—œéµå­—æ³¨å…¥é˜²è­·

2. **è¼¸å‡ºå®‰å…¨**
   - HTML å­—å…ƒè½‰ç¾©
   - XSS é˜²è­·
   - å…§å®¹é•·åº¦é™åˆ¶

3. **API å®‰å…¨**
   - API Key èªè­‰
   - Rate limiting
   - è«‹æ±‚å¤§å°é™åˆ¶

## ğŸ­ ä½¿ç”¨å ´æ™¯èˆ‡é™åˆ¶

### é©ç”¨å ´æ™¯
âœ… é‡å°ç‰¹å®šè·ç¼ºå„ªåŒ–ç¾æœ‰å±¥æ­·
âœ… åŸºæ–¼å·®è·åˆ†æçµæœé€²è¡Œæ”¹é€²
âœ… ATS å‹å–„çš„é—œéµå­—æ•´åˆ
âœ… éœ€è¦å¯è¿½è¹¤çš„å„ªåŒ–éç¨‹

### ä¸é©ç”¨å ´æ™¯
âŒ å¾é›¶é–‹å§‹å‰µå»ºå±¥æ­·
âŒ æ²’æœ‰å·®è·åˆ†æçš„ç›²ç›®å„ªåŒ–
âŒ éœ€è¦è™›æ§‹ç¶“é©—æˆ–æŠ€èƒ½ 

## ğŸš€ å„ªå‹¢ç¸½çµ

1. **æ¶æ§‹å„ªå‹¢**
   - æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œè·è²¬åˆ†é›¢
   - å…©éšæ®µç®¡ç·šï¼Œå¹³è¡Œè™•ç†èƒ½åŠ›
   - éŒ¯èª¤éš”é›¢ï¼Œå„ªé›…é™ç´š

2. **æ•ˆèƒ½å„ªå‹¢**
   - P50 < 4.5ç§’é”æ¨™
   - Token ä½¿ç”¨æ¸›å°‘ 44%
   - æˆæœ¬é™ä½ 22%

3. **å“è³ªå„ªå‹¢**
   - 100% Quick Improvements å¯¦æ–½
   - å®Œæ•´çš„æ”¹é€²è¿½è¹¤
   - è¦–è¦ºåŒ–æ¨™è¨˜ç³»çµ±

4. **ç¶­è­·å„ªå‹¢**
   - Prompt ç°¡åŒ– 47%
   - æ¸…æ™°çš„ç¨‹å¼ç¢¼çµ„ç¹”
   - å®Œå–„çš„ç›£æ§æŒ‡æ¨™

## ğŸ“Š ç›£æ§èˆ‡å¯è§€æ¸¬æ€§

### é—œéµæŒ‡æ¨™
- `resume_tailoring_v2_completed`: å®Œæˆäº‹ä»¶
- `resume_tailoring_v2_instruction_compilation_ms`: Stage 1 è€—æ™‚
- `resume_tailoring_v2_resume_writing_ms`: Stage 2 è€—æ™‚
- `improvement_count`: æ”¹é€²æ•¸é‡
- `sections_found`: ç™¼ç¾çš„ç« ç¯€æ•¸

### æ—¥èªŒè¨˜éŒ„
```python
logger.info(
    f"Resume tailoring v2.1.0-simplified completed in {total_time_ms}ms "
    f"(Compile: {stage1_ms}ms, Write: {stage2_ms}ms)"
)
```

## ğŸ”„ æœªä¾†å„ªåŒ–æ–¹å‘

### çŸ­æœŸï¼ˆ1-2 é€±ï¼‰
1. å¯¦æ–½ Gap Analysis çµæœå¿«å–
2. å„ªåŒ– HTML å¾Œè™•ç†é‚è¼¯
3. å¢åŠ æ›´å¤šèªè¨€æ”¯æ´

### ä¸­æœŸï¼ˆ1-3 æœˆï¼‰
1. Fine-tune GPT-4.1 mini å°ˆç”¨æ¨¡å‹
2. å¯¦æ–½è«‹æ±‚æ‰¹æ¬¡è™•ç†
3. å¢åŠ çµæœå¿«å–å±¤

### é•·æœŸï¼ˆ3-6 æœˆï¼‰
1. é–‹ç™¼å°ˆç”¨ AI æ¨¡å‹
2. å¯¦æ–½ä¸²æµå›æ‡‰
3. é‚Šç·£éƒ¨ç½²å„ªåŒ–

## ğŸ“ çµè«–

Resume Tailoring v2.1.0-simplified API å±•ç¾äº†å„ªç§€çš„è»Ÿé«”å·¥ç¨‹å¯¦è¸ï¼š

- **æ¸…æ™°çš„æ¶æ§‹è¨­è¨ˆ**ï¼šå…©éšæ®µç®¡ç·šï¼Œè·è²¬åˆ†é›¢
- **å„ªç•°çš„æ•ˆèƒ½è¡¨ç¾**ï¼šé”æˆæ‰€æœ‰æ•ˆèƒ½ç›®æ¨™
- **å®Œå–„çš„å“è³ªä¿è­‰**ï¼š100% æ”¹é€²å¯¦æ–½ç‡
- **è‰¯å¥½çš„å¯ç¶­è­·æ€§**ï¼šæ¨¡çµ„åŒ–ã€æ–‡æª”åŒ–ã€ç›£æ§å®Œå‚™
- **ä¼æ¥­ç´šçš„ç©©å®šæ€§**ï¼šå®Œæ•´çš„éŒ¯èª¤è™•ç†èˆ‡é™ç´šç­–ç•¥

é€™æ˜¯ä¸€å€‹æˆç†Ÿã€é«˜æ•ˆä¸”å¯æ“´å±•çš„ä¼æ¥­ç´š API å¯¦ä½œã€‚

---

**é™„éŒ„**ï¼š
- [æ¸¬è©¦æ¡ˆä¾‹](../../../test/integration/test_resume_tailoring_v2.py)
- [Prompt æ¨¡æ¿](../../../src/prompts/resume_tailoring/v2.1.0-simplified.yaml)
- [æœå‹™å¯¦ä½œ](../../../src/services/resume_tailoring.py)
- [API è·¯ç”±](../../../src/api/v1/resume_tailoring.py)