# Resume Tailoring v2.1.0-simplified å¯¦ä½œèˆ‡æ¸¬è©¦æŒ‡å—

**æ–‡æª”ç‰ˆæœ¬**: 1.0.0  
**å»ºç«‹æ—¥æœŸ**: 2025-08-11  
**åŸºæ–¼**: API_ANALYSIS_20250811.md v1.2.0  
**ç‹€æ…‹**: å¯¦ä½œå¾…é–‹å§‹

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦

æœ¬æ–‡æª”ç‚º `/api/v1/tailor-resume` API v2.1.0-simplified çš„å¯¦ä½œæŒ‡å—èˆ‡æ¸¬è©¦è¨ˆç•«ï¼ŒåŸºæ–¼ API_ANALYSIS_20250811.md ä¸­çš„æ··åˆ CSS æ¨™è¨˜æ–¹æ¡ˆã€‚

## ğŸ¯ å¯¦ä½œç›®æ¨™

### æ ¸å¿ƒåŠŸèƒ½
1. **æ··åˆ CSS æ¨™è¨˜ç³»çµ±**
   - LLM ç”Ÿæˆèªæ„æ¨™è¨˜ï¼ˆopt-modified, opt-new, opt-placeholderï¼‰
   - Python å¾Œè™•ç†åŠ å…¥é—œéµå­—æ¨™è¨˜ï¼ˆopt-keyword, opt-keyword-existingï¼‰

2. **å››ç¨®é—œéµå­—ç‹€æ…‹è¿½è¹¤**
   - still_covered â†’ ä¿ç•™çš„é—œéµå­—
   - removed â†’ è¢«ç§»é™¤çš„é—œéµå­—ï¼ˆè§¸ç™¼è­¦å‘Šï¼‰
   - newly_added â†’ æ–°å¢çš„é—œéµå­—
   - still_missing â†’ ä»ç¼ºå°‘çš„é—œéµå­—

3. **æ¨™æº–éŒ¯èª¤è™•ç†**
   - ä½¿ç”¨ VALIDATION_*, EXTERNAL_*, SYSTEM_* éŒ¯èª¤ç¢¼
   - æ”¯æ´ has_error å’Œ field_errors
   - é›™å±¤è­¦å‘Šæ©Ÿåˆ¶

## ğŸ› ï¸ å¯¦ä½œæ­¥é©Ÿ

### Step 1: å¯¦ä½œé—œéµå­—æª¢æ¸¬æ–¹æ³•

```python
# src/services/resume_tailoring.py

def _detect_keywords_presence(
    self, 
    html_content: str, 
    keywords_to_check: list[str]
) -> list[str]:
    """
    æª¢æ¸¬ HTML å…§å®¹ä¸­å“ªäº›é—œéµå­—å¯¦éš›å­˜åœ¨
    
    æ™ºèƒ½åŒ¹é…è¦å‰‡ï¼š
    - "CI/CD" â†’ å¯åŒ¹é… "CI-CD", "CI CD", "CICD"
    - "Node.js" â†’ å¯åŒ¹é… "NodeJS", "nodejs", "Node JS"
    - "Machine Learning" â†’ å¯åŒ¹é… "ML"
    """
    from bs4 import BeautifulSoup
    import re
    
    soup = BeautifulSoup(html_content, 'html.parser')
    text_content = soup.get_text(separator=' ', strip=True).lower()
    
    found_keywords = []
    for keyword in keywords_to_check:
        patterns = self._create_keyword_patterns(keyword)
        for pattern in patterns:
            if re.search(pattern, text_content, re.IGNORECASE):
                found_keywords.append(keyword)
                break
                
    return found_keywords

def _create_keyword_patterns(self, keyword: str) -> list[str]:
    """
    ç‚ºé—œéµå­—å»ºç«‹å¤šç¨®åŒ¹é…æ¨¡å¼
    """
    patterns = []
    base = re.escape(keyword)
    
    # åŸºæœ¬æ¨¡å¼
    patterns.append(base)
    
    # è™•ç†ç‰¹æ®Šæƒ…æ³
    if "/" in keyword:  # CI/CD â†’ CI-CD, CI CD
        variants = [
            keyword.replace("/", "-"),
            keyword.replace("/", " "),
            keyword.replace("/", "")
        ]
        patterns.extend([re.escape(v) for v in variants])
    
    if "." in keyword:  # Node.js â†’ NodeJS, Node JS
        variants = [
            keyword.replace(".", ""),
            keyword.replace(".", " ")
        ]
        patterns.extend([re.escape(v) for v in variants])
    
    # ç¸®å¯«å°ç…§
    abbreviations = {
        "Machine Learning": ["ML"],
        "Artificial Intelligence": ["AI"],
        "Deep Learning": ["DL"],
        "Natural Language Processing": ["NLP"]
    }
    
    if keyword in abbreviations:
        patterns.extend([re.escape(abbr) for abbr in abbreviations[keyword]])
    
    return patterns

def _categorize_keywords(
    self,
    original_resume: str,
    optimized_html: str,
    covered_keywords: list[str],
    missing_keywords: list[str]
) -> dict[str, list[str]]:
    """
    åˆ†é¡æ‰€æœ‰é—œéµå­—çš„ç‹€æ…‹è®ŠåŒ–
    """
    # æª¢æ¸¬åŸå§‹å±¥æ­·ä¸­çš„é—œéµå­—
    originally_present = self._detect_keywords_presence(
        original_resume, 
        covered_keywords or []
    )
    
    # æª¢æ¸¬å„ªåŒ–å¾Œå±¥æ­·ä¸­çš„æ‰€æœ‰é—œéµå­—
    all_keywords = list(set((covered_keywords or []) + (missing_keywords or [])))
    currently_present = self._detect_keywords_presence(
        optimized_html,
        all_keywords
    )
    
    # åˆ†é¡
    result = {
        "still_covered": [
            kw for kw in (covered_keywords or []) 
            if kw in currently_present
        ],
        "removed": [
            kw for kw in (covered_keywords or []) 
            if kw not in currently_present
        ],
        "newly_added": [
            kw for kw in (missing_keywords or []) 
            if kw in currently_present
        ],
        "still_missing": [
            kw for kw in (missing_keywords or []) 
            if kw not in currently_present
        ]
    }
    
    # è¨˜éŒ„è­¦å‘Š
    if result["removed"]:
        logger.warning(
            f"âš ï¸ Keywords removed during optimization: {result['removed']}"
        )
    
    return result
```

### Step 2: æ›´æ–° _process_optimization_result_v2 æ–¹æ³•

å·²åœ¨ API_ANALYSIS_20250811.md ä¸­è©³ç´°èªªæ˜ï¼ˆç¬¬ 547-591 è¡Œï¼‰

### Step 3: æ›´æ–° API è·¯ç”±

```python
# src/api/v1/resume_tailoring.py

# æ›´æ–° tailor_resume ç«¯é»çš„éŒ¯èª¤è™•ç†
async def tailor_resume(
    request: TailorResumeRequest,
    settings: Settings = Depends(get_settings)
) -> TailoringResponse:
    try:
        result = await tailoring_service.tailor_resume(
            job_description=request.job_description,
            original_resume=request.original_resume,
            gap_analysis=request.gap_analysis,
            language=request.options.language,
            include_markers=request.options.include_visual_markers
        )
        
        # è™•ç†é—œéµå­—ç§»é™¤è­¦å‘Š
        warning = None
        if result.get("keyword_tracking", {}).get("removed"):
            removed = result["keyword_tracking"]["removed"]
            warning = {
                "has_warning": True,
                "message": f"Optimization successful but {len(removed)} keywords removed",
                "details": removed
            }
        else:
            warning = {
                "has_warning": False,
                "message": "",
                "details": []
            }
        
        return TailoringResponse(
            success=True,
            data=result,
            error={
                "has_error": False,
                "code": "",
                "message": "",
                "details": "",
                "field_errors": {}
            },
            warning=warning
        )
        
    except ValueError as e:
        # ä½¿ç”¨ VALIDATION_* éŒ¯èª¤ç¢¼
        # è©³è¦‹ API_ANALYSIS_20250811.md ç¬¬ 936-963 è¡Œ
        pass
```

### Step 4: æ›´æ–° Pydantic æ¨¡å‹

```python
# src/models/api/resume_tailoring.py

class KeywordTracking(BaseModel):
    """é—œéµå­—è¿½è¹¤è³‡è¨Š"""
    originally_covered: list[str]
    originally_missing: list[str]
    still_covered: list[str]
    removed: list[str]
    newly_added: list[str]
    still_missing: list[str]
    coverage_change: dict[str, int]
    warnings: list[str]

class ErrorInfo(BaseModel):
    """éŒ¯èª¤è³‡è¨Šï¼ˆæ¨™æº–æ ¼å¼ï¼‰"""
    has_error: bool
    code: str
    message: str
    details: str
    field_errors: dict[str, list[str]] = {}

class WarningInfo(BaseModel):
    """è­¦å‘Šè³‡è¨Š"""
    has_warning: bool
    message: str
    details: list[str] = []

class TailoringResponse(BaseModel):
    """API å›æ‡‰æ ¼å¼"""
    success: bool
    data: TailoringResult | None
    error: ErrorInfo
    warning: WarningInfo
```

## ğŸ§ª æ¸¬è©¦è¨ˆç•«

### å–®å…ƒæ¸¬è©¦

#### UT-01: é—œéµå­—æª¢æ¸¬æ¸¬è©¦
```python
def test_detect_keywords_presence():
    """æ¸¬è©¦é—œéµå­—æª¢æ¸¬é‚è¼¯"""
    service = ResumeTailoringService()
    html = "<p>Experience with CI/CD pipelines and Node.js development</p>"
    
    # æ¸¬è©¦è®Šé«”åŒ¹é…
    found = service._detect_keywords_presence(html, ["CI-CD", "NodeJS"])
    assert "CI-CD" in found  # æ‡‰è©²åŒ¹é… CI/CD
    assert "NodeJS" in found  # æ‡‰è©²åŒ¹é… Node.js

def test_categorize_keywords():
    """æ¸¬è©¦é—œéµå­—åˆ†é¡é‚è¼¯"""
    service = ResumeTailoringService()
    
    original = "<p>Python and Django developer</p>"
    optimized = "<p>Full-stack developer with Docker expertise</p>"
    
    result = service._categorize_keywords(
        original,
        optimized,
        covered_keywords=["Python", "Django"],
        missing_keywords=["Docker", "AWS"]
    )
    
    assert result["removed"] == ["Python", "Django"]
    assert result["newly_added"] == ["Docker"]
    assert result["still_missing"] == ["AWS"]
```

#### UT-02: è­¦å‘Šç”Ÿæˆæ¸¬è©¦
```python
def test_warning_generation_for_removed_keywords():
    """æ¸¬è©¦é—œéµå­—è¢«ç§»é™¤æ™‚çš„è­¦å‘Šç”Ÿæˆ"""
    # æ¨¡æ“¬å„ªåŒ–çµæœç§»é™¤äº†åŸæœ‰é—œéµå­—
    # é©—è­‰ç”Ÿæˆæ­£ç¢ºçš„è­¦å‘Šè¨Šæ¯
    pass
```

### æ•´åˆæ¸¬è©¦

#### IT-01: å®Œæ•´æµç¨‹æ¸¬è©¦
```python
async def test_full_pipeline_with_keyword_tracking():
    """æ¸¬è©¦å®Œæ•´çš„é—œéµå­—è¿½è¹¤æµç¨‹"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.post(
            "/api/v1/tailor-resume",
            json={
                "job_description": "..." * 100,  # â‰¥200 chars
                "original_resume": "<html>..." * 50,  # â‰¥200 chars
                "gap_analysis": {
                    "core_strengths": ["Python", "Leadership"],
                    "key_gaps": ["[Skill Gap] Docker"],
                    "quick_improvements": ["Add Docker certification"],
                    "covered_keywords": ["Python", "Django"],
                    "missing_keywords": ["Docker", "Kubernetes"],
                    "coverage_percentage": 60,
                    "similarity_percentage": 70
                }
            }
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "keyword_tracking" in data["data"]
        assert data["warning"]["has_warning"] == False  # å‡è¨­æ²’æœ‰ç§»é™¤é—œéµå­—
```

#### IT-02: é—œéµå­—ç§»é™¤è­¦å‘Šæ¸¬è©¦
```python
async def test_keyword_removal_warning():
    """æ¸¬è©¦é—œéµå­—è¢«ç§»é™¤æ™‚è¿”å›è­¦å‘Šä½†ä»ç‚º 200 ç‹€æ…‹"""
    # æ§‹é€ æœƒå°è‡´é—œéµå­—è¢«ç§»é™¤çš„æ¸¬è©¦æ¡ˆä¾‹
    # é©—è­‰è¿”å› HTTP 200 + warning
    pass
```

### æ•ˆèƒ½æ¸¬è©¦

#### PT-01: é—œéµå­—æª¢æ¸¬æ•ˆèƒ½
```python
def test_keyword_detection_performance():
    """æ¸¬è©¦é—œéµå­—æª¢æ¸¬çš„æ•ˆèƒ½å½±éŸ¿"""
    # æ¸¬è©¦è™•ç† 50+ é—œéµå­—çš„æ•ˆèƒ½
    # ç¢ºä¿å¾Œè™•ç†æ™‚é–“ < 100ms
    pass
```

## ğŸ“Š æ¸¬è©¦è¦†è“‹è¦æ±‚

| æ¸¬è©¦é¡å‹ | ç›®æ¨™è¦†è“‹ç‡ | é—œéµæ¸¬è©¦é» |
|---------|-----------|-----------|
| å–®å…ƒæ¸¬è©¦ | > 90% | é—œéµå­—æª¢æ¸¬ã€åˆ†é¡ã€è­¦å‘Šç”Ÿæˆ |
| æ•´åˆæ¸¬è©¦ | > 80% | API ç«¯é»ã€éŒ¯èª¤è™•ç†ã€è­¦å‘Šæ©Ÿåˆ¶ |
| æ•ˆèƒ½æ¸¬è©¦ | 100% | P50 < 4.5s, P95 < 7.5s |

## ğŸš€ éƒ¨ç½²è¨ˆç•«

### å‰ç½®æ¢ä»¶
1. æ‰€æœ‰æ¸¬è©¦é€šé
2. Ruff æª¢æŸ¥ç„¡éŒ¯èª¤ï¼š`ruff check src/ --line-length=120`
3. æ–‡æª”æ›´æ–°å®Œæˆ

### éƒ¨ç½²æ­¥é©Ÿ
1. **æœ¬åœ°æ¸¬è©¦**
   ```bash
   pytest test/unit/test_resume_tailoring_v2.py -v
   pytest test/integration/test_resume_tailoring_v2.py -v
   ```

2. **æ€§èƒ½é©—è­‰**
   ```bash
   python test/performance/test_resume_tailoring_performance.py
   ```

3. **éƒ¨ç½²åˆ°é–‹ç™¼ç’°å¢ƒ**
   ```bash
   docker build -t resume-tailoring:v2.1.0 .
   docker run -e ENVIRONMENT=development ...
   ```

4. **ç”Ÿç”¢éƒ¨ç½²**
   - ç„¡éœ€å‘å¾Œç›¸å®¹ï¼ˆæ²’æœ‰ live usersï¼‰
   - ç›´æ¥æ›¿æ›ç¾æœ‰ç‰ˆæœ¬
   - ç›£æ§é—œéµæŒ‡æ¨™ 24 å°æ™‚

## ğŸ“ˆ æˆåŠŸæ¨™æº–

### å¿…é ˆé”æˆ
- âœ… é—œéµå­—è¿½è¹¤åŠŸèƒ½æ­£å¸¸é‹ä½œ
- âœ… è­¦å‘Šæ©Ÿåˆ¶æ­£ç¢ºè§¸ç™¼
- âœ… P50 < 4.5s, P95 < 7.5s
- âœ… æ‰€æœ‰æ¸¬è©¦é€šé
- âœ… Ruff æª¢æŸ¥ç„¡éŒ¯èª¤

### ç›£æ§æŒ‡æ¨™
- keyword_removal_rate: é—œéµå­—è¢«ç§»é™¤çš„æ¯”ç‡
- warning_trigger_rate: è­¦å‘Šè§¸ç™¼ç‡
- response_time_p50/p95: å›æ‡‰æ™‚é–“ç™¾åˆ†ä½æ•¸

## ğŸ”„ å›æ»¾è¨ˆç•«

å¦‚æœéƒ¨ç½²å¾Œç™¼ç¾åš´é‡å•é¡Œï¼š
1. ç«‹å³å›æ»¾åˆ° v2.0.0 ç‰ˆæœ¬
2. åˆ†ææ—¥èªŒæ‰¾å‡ºå•é¡Œ
3. ä¿®å¾©å¾Œé‡æ–°éƒ¨ç½²

---

**æœ€å¾Œæ›´æ–°**: 2025-08-11  
**åŸºæ–¼**: API_ANALYSIS_20250811.md v1.2.0  
**ç‹€æ…‹**: å¾…å¯¦ä½œ