# å®Œæ•´ç¶“é©—æ•™è¨“ç¸½çµ - Index Cal & Gap Analysis Evolution

**æ–‡æª”ç‰ˆæœ¬**: 2.0.0  
**å»ºç«‹æ—¥æœŸ**: 2025-08-05  
**æœ€å¾Œæ›´æ–°**: 2025-08-16  
**ä½œè€…**: AI Resume Advisor Team  
**æ•´åˆä¾†æº**: V2/V3/V4 ä¸‰å€‹ç‰ˆæœ¬çš„é–‹ç™¼ç¶“é©—

---

## ğŸš¨ æœ€é‡è¦çš„ç¶“é©—æ•™è¨“ï¼šLLM Factory ä½¿ç”¨è¦ç¯„

**æœ¬æ¬¡æ¸¬è©¦ä¿®å¾©éç¨‹ä¸­ï¼Œæœ€è€—æ™‚çš„å•é¡Œä¹‹ä¸€å°±æ˜¯ Claude Code é•å LLM Factory ä½¿ç”¨è¦ç¯„**

### å•é¡Œæè¿°
- **éŒ¯èª¤**: 9 å€‹æœå‹™ç›´æ¥ä½¿ç”¨ `get_azure_openai_client()` å°è‡´ 500 éŒ¯èª¤
- **åŸå› **: Claude Code ç¿’æ…£ç›´æ¥ä½¿ç”¨ OpenAI SDKï¼Œä¸çŸ¥é“å°ˆæ¡ˆæœ‰çµ±ä¸€çš„ LLM ç®¡ç†æ©Ÿåˆ¶
- **å½±éŸ¿**: è€—è²»å¤§é‡æ™‚é–“è¨ºæ–· "deployment does not exist" éŒ¯èª¤
- **æ•™è¨“**: å¿…é ˆåœ¨ CLAUDE.local.md ä¸­æ˜ç¢ºå‘ŠçŸ¥æ­¤è¦å‰‡

### é—œéµè¦å‰‡
```python
# âŒ çµ•å°ç¦æ­¢ - Claude Code å¸¸çŠ¯çš„éŒ¯èª¤
from openai import AsyncAzureOpenAI
from src.services.openai_client import get_azure_openai_client

# âœ… å”¯ä¸€æ­£ç¢ºçš„æ–¹å¼
from src.services.llm_factory import get_llm_client
client = get_llm_client(api_name="gap_analysis")
```

**è«‹å‹™å¿…è¨˜ä½**: æœ¬å°ˆæ¡ˆæ‰€æœ‰ LLM èª¿ç”¨éƒ½å¿…é ˆé€šé LLM Factoryï¼Œé€™æ˜¯å¼·åˆ¶è¦å®šï¼

---

## ğŸ“Š åŸ·è¡Œæ‘˜è¦

æœ¬æ–‡æª”æ•´åˆäº† Index Cal and Gap Analysis V2 é‡æ§‹éç¨‹ä¸­çš„æ¸¬è©¦å¯¦ä½œç¶“é©—ï¼Œæ¶µè“‹æ•´åˆæ¸¬è©¦ã€æ•ˆèƒ½æ¸¬è©¦ã€E2E æ¸¬è©¦çš„è¨ºæ–·ã€ä¿®å¾©å’Œç¶“é©—æ•™è¨“ã€‚

### é—œéµæˆå°±
- **æ•´åˆæ¸¬è©¦é€šéç‡**: 7.1% â†’ 100% (æå‡ 1308%)
- **æ•ˆèƒ½æ¸¬è©¦æˆåŠŸç‡**: 0% â†’ 100% (P50 < 20s é”æ¨™)
- **æ¸¬è©¦ç’°å¢ƒå•é¡Œ**: SSL é€£æ¥ã€Mock è¡çªå…¨éƒ¨è§£æ±º
- **ä¿®å¾©æ™‚é–“**: ç¸½è¨ˆç´„ 8 å°æ™‚å®Œæˆæ‰€æœ‰æ¸¬è©¦ä¿®å¾©

---

## ğŸ—ï¸ ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´åˆæ¸¬è©¦ä¿®å¾©ç¶“é©—

### 1.1 å•é¡Œæ¼”é€²èˆ‡è§£æ±ºè·¯å¾‘

#### éšæ®µ 1: ç’°å¢ƒéš”é›¢å•é¡Œ (7.1% â†’ 64.3%)
**å•é¡Œæ ¹æº**ï¼š
- SSL è­‰æ›¸é©—è­‰å¤±æ•—
- æ¸¬è©¦èˆ‡ç”Ÿç”¢ç’°å¢ƒè®Šæ•¸æ··æ·†
- V1/V2 å¯¦ä½œåˆ‡æ›å•é¡Œ

**é—œéµä¿®å¾©**ï¼š
```python
# ç’°å¢ƒè®Šæ•¸éš”é›¢
@pytest.fixture(autouse=True)
def setup_test_environment():
    """å®Œå…¨éš”é›¢çš„æ¸¬è©¦ç’°å¢ƒè¨­ç½®"""
    original_env = os.environ.copy()
    
    # æ¸…ç†å¯èƒ½å¹²æ“¾çš„ç’°å¢ƒè®Šæ•¸
    for key in list(os.environ.keys()):
        if key.startswith(('AZURE_', 'OPENAI_', 'EMBEDDING_')):
            del os.environ[key]
    
    # è¨­ç½®æ¸¬è©¦å°ˆç”¨é…ç½®
    os.environ.update({
        'USE_V2_IMPLEMENTATION': 'true',
        'ENVIRONMENT': 'test',
        'TESTING': 'true'
    })
    
    yield
    
    # æ¢å¾©åŸå§‹ç’°å¢ƒ
    os.environ.clear()
    os.environ.update(original_env)
```

#### éšæ®µ 2: API è¼¸å…¥é©—è­‰å¯¦ä½œ (64.3% â†’ 100%)
**ç¼ºå¤±åŠŸèƒ½**ï¼š
- æœ€å°é•·åº¦é©—è­‰ (200 å­—å…ƒ)
- èªè¨€ç™½åå–®é©—è­‰
- è¶…æ™‚éŒ¯èª¤è™•ç†
- é™é€ŸéŒ¯èª¤è™•ç†

**Pydantic é©—è­‰å™¨å¯¦ä½œ**ï¼š
```python
class IndexCalAndGapAnalysisRequest(BaseModel):
    """å¢å¼·çš„è«‹æ±‚æ¨¡å‹ï¼ŒåŒ…å«å®Œæ•´é©—è­‰"""
    
    resume: str = Field(
        ..., 
        min_length=200,
        description="Resume content (min 200 chars)"
    )
    job_description: str = Field(
        ..., 
        min_length=200,
        description="Job description (min 200 chars)"
    )
    language: str = Field(
        default="en", 
        description="Output language (en or zh-TW)"
    )

    @validator('language')
    def validate_language(cls, v):
        valid_languages = {'en', 'zh-tw', 'zh-TW'}
        if v.lower() not in {lang.lower() for lang in valid_languages}:
            raise ValueError(f"Unsupported language: {v}. Supported: en, zh-TW")
        return 'zh-TW' if v.lower() == 'zh-tw' else v

    @validator('resume', 'job_description')
    def validate_content_length(cls, v, field):
        if len(v.strip()) < 200:
            raise ValueError(f"{field.name} must be at least 200 characters long")
        return v.strip()
```

### 1.2 éŒ¯èª¤è™•ç†å¢å¼·

```python
# çµ±ä¸€éŒ¯èª¤ä»£ç¢¼å®šç¾©
class ErrorCodes:
    VALIDATION_ERROR = "VALIDATION_ERROR"
    TEXT_TOO_SHORT = "TEXT_TOO_SHORT"
    INVALID_LANGUAGE = "INVALID_LANGUAGE"
    TIMEOUT_ERROR = "TIMEOUT_ERROR"
    RATE_LIMIT_ERROR = "RATE_LIMIT_ERROR"

# API ç«¯é»éŒ¯èª¤è™•ç†
async def calculate_index_and_analyze_gap(
    request: IndexCalAndGapAnalysisRequest,
    req: Request
) -> UnifiedResponse:
    try:
        # æ¥­å‹™é‚è¼¯
        pass
        
    except ValidationError as e:
        # Pydantic é©—è­‰éŒ¯èª¤è™•ç†
        error_details = [f"{err['loc'][-1]}: {err['msg']}" for err in e.errors()]
        raise HTTPException(
            status_code=400,
            detail=create_validation_error_response(
                field="request",
                message="; ".join(error_details)
            ).model_dump()
        )
    
    except asyncio.TimeoutError:
        # è¶…æ™‚éŒ¯èª¤è™•ç†
        raise HTTPException(
            status_code=408,
            detail=create_error_response(
                code=ErrorCodes.TIMEOUT_ERROR,
                message="Request timed out",
                details="The request took too long to process"
            ).model_dump()
        )
```

### 1.3 æ¸¬è©¦ç’°å¢ƒ Mock ç­–ç•¥

```python
# conftest.py - å…¨å±€ Mock è¨­ç½®
@pytest.fixture(autouse=True)
def mock_openai_services():
    """Mock æ‰€æœ‰ OpenAI æœå‹™ï¼Œé¿å…çœŸå¯¦ API èª¿ç”¨"""
    with patch('src.services.llm_factory.get_llm_client') as mock_llm:
        # è¨­ç½® Mock è¡Œç‚º
        mock_client = Mock()
        mock_llm.return_value = mock_client
        
        # æ¨¡æ“¬ API å›æ‡‰
        mock_response = Mock()
        mock_response.choices = [Mock(message=Mock(content="..."))]
        mock_client.chat.completions.create = AsyncMock(return_value=mock_response)
        
        yield mock_llm
```

---

## ğŸš€ ç¬¬äºŒéƒ¨åˆ†ï¼šæ•ˆèƒ½æ¸¬è©¦è¨ºæ–·èˆ‡ä¿®å¾©

### 2.1 å•é¡Œè¨ºæ–·æµç¨‹

#### éŒ¯èª¤æ¼”é€²æ­·å²
```
1. LLM Factory é•è¦ (500 éŒ¯èª¤) 
   â†“ [ä¿®å¾©: çµ±ä¸€ä½¿ç”¨ get_llm_client]
2. JSON è§£æå¤±æ•— (500 éŒ¯èª¤)
   â†“ [ä¿®å¾©: Prompt æ ¼å¼çµ±ä¸€]  
3. API é©—è­‰éŒ¯èª¤ (400 éŒ¯èª¤)
   â†“ [ä¿®å¾©: å‹æ…‹è½‰æ›é‚è¼¯]
4. æ¸¬è©¦é€šé âœ…
```

### 2.2 é—œéµå•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### å•é¡Œ 1: LLM Factory é•è¦
**æ ¹æœ¬åŸå› **: 9 å€‹æœå‹™ç›´æ¥ä½¿ç”¨ `get_azure_openai_client()` è€Œé LLM Factory

**éŒ¯èª¤æ¨¡å¼**ï¼š
```python
# âŒ éŒ¯èª¤ï¼šç›´æ¥ä½¿ç”¨ OpenAI Clientï¼ˆClaude Code å¸¸çŠ¯éŒ¯èª¤ï¼‰
from src.services.openai_client import get_azure_openai_client
openai_client = get_azure_openai_client()  # é»˜èªä½¿ç”¨ä¸å­˜åœ¨çš„ "gpt-4o-2"

# âŒ éŒ¯èª¤ï¼šClaude Code ç¿’æ…£ç›´æ¥ä½¿ç”¨ OpenAI SDK
from openai import AsyncAzureOpenAI
client = AsyncAzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

# âœ… æ­£ç¢ºï¼šä½¿ç”¨ LLM Factoryï¼ˆå°ˆæ¡ˆçµ±ä¸€è¦ç¯„ï¼‰
from src.services.llm_factory import get_llm_client
openai_client = get_llm_client(api_name="gap_analysis")  # è‡ªå‹•æ˜ å°„åˆ° "gpt-4.1-japan"
```

**ç‚ºä»€éº¼ Claude Code æœƒçŠ¯é€™å€‹éŒ¯èª¤**ï¼š
- Claude Code è¢«è¨“ç·´æ™‚å¤§é‡æ¥è§¸ç›´æ¥ä½¿ç”¨ OpenAI SDK çš„ç¨‹å¼ç¢¼
- ä¸äº†è§£æœ¬å°ˆæ¡ˆæœ‰çµ±ä¸€çš„ LLM ç®¡ç†æ©Ÿåˆ¶
- éœ€è¦åœ¨ CLAUDE.local.md ä¸­æ˜ç¢ºå‘ŠçŸ¥æ­¤è¦å‰‡

**LLM Factory éƒ¨ç½²æ˜ å°„**ï¼š
```python
DEPLOYMENT_MAP = {
    "gpt4o-2": "gpt-4.1-japan",
    "gpt41-mini": "gpt-4-1-mini-japaneast"
}
```

#### å•é¡Œ 3: ç¡¬ç·¨ç¢¼é…ç½®å€¼å’Œ JSON æˆªæ–·å•é¡Œ
**æ ¹æœ¬åŸå› **: 
1. ç¨‹å¼ç¢¼ä¸­ç¡¬ç·¨ç¢¼ max_tokens å€¼ï¼ˆ1500/3000ï¼‰ï¼Œè€Œéå¾ YAML è®€å–
2. JSON å›æ‡‰å›  token é™åˆ¶è¢«æˆªæ–·ï¼Œå°è‡´è§£æå¤±æ•—
3. Prompt æ¨¡æ¿ä½¿ç”¨ .format() èˆ‡ JSON å¤§æ‹¬è™Ÿè¡çª

**éŒ¯èª¤ç—‡ç‹€**ï¼š
```
JSONDecodeError: Expecting property name enclosed in double quotes: line 15 column 3 (char 378)
Response preview: '
  "CoreStrengths"'  # æ˜é¡¯çš„æˆªæ–·
```

**ä¿®å¾©å¯¦ä½œ**ï¼š

1. **å‹•æ…‹é…ç½®è¼‰å…¥ç³»çµ±**ï¼š
```python
def _load_llm_config(self, language: str, resume: str = "", job_description: str = "") -> dict[str, Any]:
    """
    è¼‰å…¥ LLM é…ç½®ï¼Œå„ªå…ˆé †åºï¼š
    1. YAML é…ç½®æª”æ¡ˆ
    2. ç’°å¢ƒè®Šæ•¸ï¼ˆè¦†è“‹ï¼‰
    3. å‹•æ…‹è¨ˆç®—ï¼ˆåŸºæ–¼è¼¸å…¥å¤§å°ï¼‰
    4. é è¨­å€¼
    """
    config = {
        "temperature": 0.3,
        "max_tokens": 3000,
        "additional_params": {}
    }
    
    # å¾ YAML è¼‰å…¥
    filename = "v2.0.0-zh-TW.yaml" if language == "zh-TW" else "v2.0.0.yaml"
    prompt_config = prompt_manager.load_prompt_config_by_filename("gap_analysis", filename)
    
    # ç’°å¢ƒè®Šæ•¸è¦†è“‹
    if os.getenv("GAP_ANALYSIS_MAX_TOKENS"):
        config["max_tokens"] = int(os.getenv("GAP_ANALYSIS_MAX_TOKENS"))
    
    # å‹•æ…‹ token è¨ˆç®—
    calculated_tokens = self._calculate_required_tokens(resume, job_description)
    if calculated_tokens > config["max_tokens"]:
        config["max_tokens"] = calculated_tokens
    
    return config
```

2. **Token è¨ˆç®—é‚è¼¯**ï¼š
```python
def _calculate_required_tokens(self, resume: str, job_description: str) -> int:
    """åŸºæ–¼è¼¸å…¥å¤§å°è¨ˆç®—æ‰€éœ€ tokens"""
    chars_per_token = 3  # ç¶“é©—å€¼ï¼š1 token â‰ˆ 3 å­—å…ƒ
    input_chars = len(resume) + len(job_description)
    estimated_input_tokens = input_chars // chars_per_token
    
    base_output_tokens = 2500  # Gap Analysis åŸºæœ¬éœ€æ±‚
    
    # å¤§è¼¸å…¥éœ€è¦æ›´å¤šè¼¸å‡ºç©ºé–“
    if estimated_input_tokens > 2000:
        base_output_tokens += int(base_output_tokens * 0.2)
    
    return base_output_tokens
```

3. **JSON å®Œæ•´æ€§æª¢æŸ¥èˆ‡ä¿®å¾©**ï¼š
```python
def _is_json_complete(self, json_str: str) -> bool:
    """æª¢æŸ¥ JSON æ˜¯å¦å®Œæ•´"""
    open_braces = json_str.count('{')
    close_braces = json_str.count('}')
    open_brackets = json_str.count('[')
    close_brackets = json_str.count(']')
    
    return (open_braces == close_braces and 
            open_brackets == close_brackets and
            bool(re.search(r'[}\]]\s*$', json_str)))

def _attempt_json_repair(self, json_str: str) -> str:
    """å˜—è©¦ä¿®å¾©æˆªæ–·çš„ JSON"""
    # è£œå……ç¼ºå¤±çš„æ‹¬è™Ÿ
    for _ in range(json_str.count('[') - json_str.count(']')):
        json_str += ']'
    for _ in range(json_str.count('{') - json_str.count('}')):
        json_str += '}'
    
    # ä¿®å¾©å°¾éš¨é€—è™Ÿ
    json_str = re.sub(r',\s*}', '}', json_str)
    json_str = re.sub(r',\s*]', ']', json_str)
    
    return json_str
```

4. **Prompt æ ¼å¼åŒ–ä¿®å¾©**ï¼š
```python
# âŒ éŒ¯èª¤ï¼šä½¿ç”¨ format() æœƒèˆ‡ JSON å¤§æ‹¬è™Ÿè¡çª
enhanced_prompt = base_prompt.format(
    job_description=job_description,
    resume=resume
)

# âœ… æ­£ç¢ºï¼šä½¿ç”¨ replace() é¿å…å¤§æ‹¬è™Ÿå•é¡Œ
enhanced_prompt = base_prompt.replace("{job_description}", job_description)
enhanced_prompt = enhanced_prompt.replace("{resume}", resume)
```

**é—œéµå­¸ç¿’é»**ï¼š
1. **æ°¸ä¸ç¡¬ç·¨ç¢¼é…ç½®å€¼** - æ‰€æœ‰é…ç½®éƒ½æ‡‰è©²å¯å¾å¤–éƒ¨èª¿æ•´
2. **å¯¦ä½œé…ç½®å„ªå…ˆé †åºéˆ** - YAML â†’ ç’°å¢ƒè®Šæ•¸ â†’ å‹•æ…‹è¨ˆç®— â†’ é è¨­å€¼
3. **ç‚º LLM è¼¸å‡ºé ç•™å……è¶³ç©ºé–“** - å‹•æ…‹è¨ˆç®—è€Œéå›ºå®šå€¼
4. **è™•ç† JSON æˆªæ–·** - æª¢æ¸¬ä¸¦å˜—è©¦ä¿®å¾©ä¸å®Œæ•´çš„ JSON
5. **æ­£ç¢ºè™•ç†æ¨¡æ¿å­—ä¸²** - ç•¶æ¨¡æ¿åŒ…å« JSON æ™‚ä½¿ç”¨ replace() è€Œé format()

**é é˜²æªæ–½**ï¼š
- å»ºç«‹é…ç½®è¼‰å…¥çš„å–®å…ƒæ¸¬è©¦
- ç›£æ§ JSON è§£æå¤±æ•—ç‡
- è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„ token æ•¸é‡ä»¥èª¿å„ªè¨ˆç®—é‚è¼¯
- åœ¨é–‹ç™¼ç’°å¢ƒå•Ÿç”¨è©³ç´°æ—¥èªŒä»¥è¿½è¹¤é…ç½®ä¾†æº

$2

#### æ¸¬è©¦åŸ·è¡Œæ¨¡å¼å°æ¯”
```python
# ä½µç™¼åŸ·è¡Œï¼ˆåŸå§‹æ–¹å¼ï¼‰
async def run_concurrent_requests(num_requests=5):
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(make_request, i) for i in range(num_requests)]
        results = [f.result() for f in futures]
    return results

# é †åºåŸ·è¡Œï¼ˆè¨ºæ–·æ¨¡å¼ï¼‰
def run_sequential_requests(num_requests=5):
    results = []
    for i in range(num_requests):
        result = make_request(i)
        results.append(result)
    return results
```

#### æ•ˆèƒ½æ¸¬è©¦çµæœ
| æŒ‡æ¨™ | é †åºåŸ·è¡Œ | ä¸¦è¡ŒåŸ·è¡Œ | ç›®æ¨™ |
|------|----------|----------|------|
| P50 éŸ¿æ‡‰æ™‚é–“ | 19.009s âœ… | 25.032s âŒ | < 20s |
| P95 éŸ¿æ‡‰æ™‚é–“ | 24.892s âœ… | 24.484s âœ… | < 30s |
| ç¸½åŸ·è¡Œæ™‚é–“ | 95.7s | 26.7s | - |
| æˆåŠŸç‡ | 100% | 100% | 100% |

---

## ğŸ”§ ç¬¬ä¸‰éƒ¨åˆ†ï¼šE2E æ¸¬è©¦ç¨ç«‹åŸ·è¡Œæ–¹æ¡ˆ

### 3.1 å•é¡ŒèƒŒæ™¯

**å…¨å±€ Mock è¡çª**ï¼š
- `test/conftest.py` çš„ `autouse=True` fixture è‡ªå‹• mock æ‰€æœ‰ API
- E2E æ¸¬è©¦éœ€è¦çœŸå¯¦ API èª¿ç”¨
- ç„¡æ³•ç°¡å–®åœ°è¦†è“‹å…¨å±€ Mock

### 3.2 ç¨ç«‹åŸ·è¡Œç’°å¢ƒè¨­è¨ˆ

#### ç›®éŒ„çµæ§‹
```
test/
â”œâ”€â”€ e2e_standalone/                    # ç¨ç«‹çš„ E2E æ¸¬è©¦ç›®éŒ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                    # ç„¡ mock çš„æ¸¬è©¦é…ç½®
â”‚   â”œâ”€â”€ run_e2e_tests.py              # Python åŸ·è¡Œè…³æœ¬
â”‚   â””â”€â”€ test_gap_analysis_v2_e2e.py   # æ¸¬è©¦æª”æ¡ˆ
â””â”€â”€ scripts/
    â””â”€â”€ run_e2e_standalone.sh          # Shell åŸ·è¡Œè…³æœ¬
```

#### ç„¡ Mock çš„ conftest.py
```python
# test/e2e_standalone/conftest.py
import os
import pytest
from dotenv import load_dotenv

# è¼‰å…¥çœŸå¯¦ç’°å¢ƒè®Šæ•¸
load_dotenv(override=True)

@pytest.fixture(autouse=True)
def setup_e2e_environment():
    """è¨­ç½® E2E æ¸¬è©¦ç’°å¢ƒ - ä½¿ç”¨çœŸå¯¦ API"""
    os.environ.update({
        'USE_V2_IMPLEMENTATION': 'true',
        'ENABLE_PARTIAL_RESULTS': 'true',
        'RESOURCE_POOL_ENABLED': 'false',  # ç°¡åŒ–æ¸¬è©¦
        'REAL_E2E_TEST': 'true'
    })
    
    yield
    
    if 'REAL_E2E_TEST' in os.environ:
        del os.environ['REAL_E2E_TEST']

@pytest.fixture
def skip_if_no_api_keys():
    """æª¢æŸ¥å¿…è¦çš„ API å¯†é‘°"""
    required_keys = [
        'AZURE_OPENAI_API_KEY',
        'AZURE_OPENAI_ENDPOINT',
        'EMBEDDING_API_KEY'
    ]
    
    missing_keys = [key for key in required_keys if not os.environ.get(key)]
    if missing_keys:
        pytest.skip(f"E2E tests require real API keys. Missing: {', '.join(missing_keys)}")
```

#### Python åŸ·è¡Œè…³æœ¬
```python
#!/usr/bin/env python
# test/e2e_standalone/run_e2e_tests.py
import subprocess
import sys
import os
from pathlib import Path

def main():
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    
    env = os.environ.copy()
    env['PYTHONPATH'] = str(project_root / 'src')
    env['RUNNING_STANDALONE_E2E'] = 'true'
    
    cmd = [
        sys.executable, '-m', 'pytest',
        'test_gap_analysis_v2_e2e.py',
        '-v', '-s',
        '--tb=short',
        '--confcutdir=.',  # é™åˆ¶ conftest.py æœç´¢ç¯„åœ
        '--no-cov',
        '-p', 'no:warnings'
    ]
    
    cmd.extend(sys.argv[1:])
    
    print("ğŸš€ Running E2E Tests in Standalone Mode")
    result = subprocess.run(cmd, env=env, cwd=str(script_dir))
    sys.exit(result.returncode)

if __name__ == '__main__':
    main()
```

---

## ğŸ“š ç¬¬å››éƒ¨åˆ†ï¼šç¶œåˆç¶“é©—æ•™è¨“

### 4.1 æ¶æ§‹è¨­è¨ˆåŸå‰‡

1. **çµ±ä¸€æŠ½è±¡å±¤çš„é‡è¦æ€§ï¼ˆClaude Code ç‰¹åˆ¥æ³¨æ„ï¼‰**
   - LLM Factory æ¨¡å¼é¿å… deployment é…ç½®åˆ†æ•£
   - æ‰€æœ‰ LLM èª¿ç”¨å¿…é ˆé€šéçµ±ä¸€å…¥å£
   - é›†ä¸­ç®¡ç†æ¨¡å‹æ˜ å°„å’ŒéŒ¯èª¤è™•ç†
   
   **âš ï¸ Claude Code å¸¸è¦‹éŒ¯èª¤**ï¼š
   - Claude Code ç¿’æ…£ç›´æ¥ä½¿ç”¨ OpenAI SDK æˆ– Azure OpenAI Client
   - é€™åœ¨æœ¬å°ˆæ¡ˆä¸­æ˜¯çµ•å°ç¦æ­¢çš„ï¼Œå› ç‚ºæˆ‘å€‘æœ‰çµ±ä¸€çš„ LLM ç®¡ç†æ©Ÿåˆ¶
   - é•åæ­¤è¦å‰‡æœƒå°è‡´ 500 éŒ¯èª¤ï¼š"deployment does not exist"

2. **å‘å¾Œå…¼å®¹æ€§è¨­è¨ˆ**
   - V2 å¿…é ˆæ­£ç¢ºè™•ç† V1 çš„æ‰€æœ‰è³‡æ–™æ ¼å¼
   - å‹æ…‹è½‰æ›éœ€è¦æ˜ç¢ºçš„é©—è­‰å’ŒéŒ¯èª¤è™•ç†
   - ä¿ç•™å›é€€æ©Ÿåˆ¶ä½†è¦ç¢ºä¿å‹æ…‹ä¸€è‡´æ€§

3. **æ¸¬è©¦ç’°å¢ƒéš”é›¢**
   - é–‹ç™¼ã€æ¸¬è©¦ã€ç”Ÿç”¢ç’°å¢ƒè®Šæ•¸å®Œå…¨éš”é›¢
   - Mock ç­–ç•¥éœ€è¦è€ƒæ…®ä¸åŒæ¸¬è©¦é¡å‹çš„éœ€æ±‚
   - E2E æ¸¬è©¦éœ€è¦ç¨ç«‹çš„åŸ·è¡Œç’°å¢ƒ

### 4.2 è¨ºæ–·æ–¹æ³•è«–

#### ç³»çµ±æ€§è¨ºæ–·æµç¨‹
```
Phase 1: ç’°å¢ƒé…ç½®æª¢æŸ¥ (P0)
â”œâ”€â”€ æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
â”œâ”€â”€ é©—è­‰æœå‹™é…ç½®  
â””â”€â”€ ç¢ºèªä¾è³´ç‰ˆæœ¬

Phase 2: æ ¸å¿ƒæœå‹™æª¢æŸ¥ (P1)
â”œâ”€â”€ è¿½è¹¤ API å‘¼å«éˆ
â”œâ”€â”€ æª¢æŸ¥è³‡æ–™æµè½‰æ›
â””â”€â”€ é©—è­‰éŒ¯èª¤è™•ç†

Phase 3: æ¸¬è©¦é‚è¼¯å„ªåŒ–
â”œâ”€â”€ ç°¡åŒ–è¤‡é›œåº¦ï¼ˆç§»é™¤ä½µç™¼ï¼‰
â”œâ”€â”€ å¢åŠ è©³ç´°æ—¥èªŒ
â””â”€â”€ é€æ­¥ç¸®å°å•é¡Œç¯„åœ
```

#### é—œéµè¨ºæ–·æŠ€å·§
1. **ç°¡åŒ–æ¸¬è©¦ç’°å¢ƒ**: ç§»é™¤ä½µç™¼ç­‰è¤‡é›œæ€§ï¼Œå°ˆæ³¨æ ¸å¿ƒå•é¡Œ
2. **åˆ©ç”¨éŒ¯èª¤ä¿¡æ¯**: ä»”ç´°é–±è®€å®Œæ•´éŒ¯èª¤å †ç–Š
3. **ä½¿ç”¨é©ç•¶å·¥å…·**: Serena MCP å·¥å…·ç²¾ç¢ºåˆ†æä»£ç¢¼

### 4.3 æ¸¬è©¦ç­–ç•¥æœ€ä½³å¯¦è¸

1. **åˆ†å±¤æ¸¬è©¦æ¶æ§‹**
   - å–®å…ƒæ¸¬è©¦: Mock æ‰€æœ‰å¤–éƒ¨ä¾è³´
   - æ•´åˆæ¸¬è©¦: Mock å¤–éƒ¨ APIï¼Œæ¸¬è©¦å…§éƒ¨æ•´åˆ
   - æ•ˆèƒ½æ¸¬è©¦: ä½¿ç”¨çœŸå¯¦ APIï¼Œæ¸¬é‡å¯¦éš›æ•ˆèƒ½
   - E2E æ¸¬è©¦: å®Œå…¨çœŸå¯¦ç’°å¢ƒï¼Œç«¯åˆ°ç«¯é©—è­‰

2. **Mock ç­–ç•¥**
   ```python
   # æ•´åˆæ¸¬è©¦ - éƒ¨åˆ† Mock
   @patch('src.services.llm_factory.get_llm_client')
   def test_integration(mock_llm):
       # Mock LLM ä½†ä¿ç•™å…¶ä»–æœå‹™çœŸå¯¦
       pass
   
   # æ•ˆèƒ½æ¸¬è©¦ - ç„¡ Mock
   def test_performance():
       # ä½¿ç”¨çœŸå¯¦ API
       load_dotenv()  # è¼‰å…¥çœŸå¯¦é…ç½®
       # åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
   ```

3. **éŒ¯èª¤è™•ç†æ¸¬è©¦**
   - æ¸¬è©¦å„ç¨®éŒ¯èª¤å ´æ™¯ï¼ˆè¶…æ™‚ã€é™é€Ÿã€é©—è­‰å¤±æ•—ï¼‰
   - ç¢ºä¿éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼ä¸€è‡´
   - é©—è­‰éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶

### 4.4 ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥æ¸…å–®

**é‡åˆ°æ¸¬è©¦å¤±æ•—æ™‚çš„ç³»çµ±æª¢æŸ¥æ­¥é©Ÿ**ï¼š

- [ ] æª¢æŸ¥ LLM Factory ä½¿ç”¨ï¼ˆæœå°‹ `get_azure_openai_client` ç›´æ¥å‘¼å«ï¼‰
- [ ] é©—è­‰ Prompt æª”æ¡ˆæ ¼å¼èˆ‡è§£æå™¨é æœŸä¸€è‡´
- [ ] æª¢æŸ¥è³‡æ–™å‹æ…‹è½‰æ›ï¼ˆç‰¹åˆ¥æ˜¯ list/dict â†’ strï¼‰
- [ ] é©—è­‰å­—æ®µåæ˜ å°„ï¼ˆV1 â†’ V2 æ ¼å¼ï¼‰
- [ ] ç¢ºèªç’°å¢ƒè®Šæ•¸è¨­ç½®æ­£ç¢º
- [ ] æª¢æŸ¥ Mock è¨­ç½®æ˜¯å¦å½±éŸ¿æ¸¬è©¦
- [ ] è€ƒæ…®æš«æ™‚ç°¡åŒ–æ¸¬è©¦ä»¥ä¾¿è¨ºæ–·
- [ ] ä½¿ç”¨ Ruff ç¢ºä¿ç¨‹å¼ç¢¼å“è³ª

### 4.5 å»ºè­°æ”¹é€²æªæ–½

#### çŸ­æœŸæ”¹é€²
1. **å‹æ…‹æª¢æŸ¥å¢å¼·**
   ```python
   # ä½¿ç”¨ TypeVar å’Œ Generic æé«˜å‹æ…‹å®‰å…¨
   from typing import TypeVar, Generic
   
   T = TypeVar('T')
   
   class SafeConverter(Generic[T]):
       def convert(self, value: Any) -> T:
           # æ˜ç¢ºçš„å‹æ…‹è½‰æ›å’Œé©—è­‰
           pass
   ```

2. **æ¸¬è©¦æ¨¡å¼é–‹é—œ**
   ```python
   # ç’°å¢ƒè®Šæ•¸æ§åˆ¶æ¸¬è©¦è¡Œç‚º
   TEST_MODE = os.getenv('TEST_MODE', 'mock')  # mock, integration, real
   PERF_TEST_CONCURRENCY = int(os.getenv('PERF_TEST_CONCURRENCY', '1'))
   ```

#### é•·æœŸæ”¹é€²
1. **å®Œæ•´çš„å‹æ…‹ç³»çµ±**: è€ƒæ…®ä½¿ç”¨ mypy strict mode
2. **ç›£æ§ç³»çµ±å¢å¼·**: è¿½è¹¤æ¸¬è©¦åŸ·è¡Œæ™‚é–“å’ŒæˆåŠŸç‡è¶¨å‹¢
3. **è‡ªå‹•åŒ–è¨ºæ–·å·¥å…·**: å»ºç«‹å•é¡Œè¨ºæ–·è…³æœ¬

---

## ğŸ çµè«–

é€™æ¬¡ Index Cal and Gap Analysis V2 çš„æ¸¬è©¦å¯¦ä½œéç¨‹å……æ»¿æŒ‘æˆ°ï¼Œä½†ä¹Ÿå¸¶ä¾†å¯¶è²´çš„ç¶“é©—ï¼š

### æœ€é‡è¦çš„æ•™è¨“ - Claude Code ä½¿ç”¨æ³¨æ„äº‹é …
**LLM Factory é•è¦å•é¡Œæ˜¯æœ¬æ¬¡æ¸¬è©¦ä¿®å¾©æœ€è€—æ™‚çš„éƒ¨åˆ†**ã€‚Claude Code å› ç‚ºè¨“ç·´è³‡æ–™çš„é—œä¿‚ï¼Œç¿’æ…£ç›´æ¥ä½¿ç”¨ OpenAI SDKï¼Œä½†é€™åœ¨æœ¬å°ˆæ¡ˆä¸­æ˜¯çµ•å°ç¦æ­¢çš„ã€‚æœªä¾†å¿…é ˆï¼š
1. åœ¨ CLAUDE.local.md ä¸­æ˜ç¢ºæ¨™ç¤ºæ­¤è¦å‰‡ç‚ºæœ€é«˜å„ªå…ˆç´š
2. æ¯æ¬¡ Claude Code å¯¦ä½œ LLM ç›¸é—œåŠŸèƒ½æ™‚ï¼Œä¸»å‹•æé†’ä½¿ç”¨ LLM Factory
3. Code Review æ™‚å„ªå…ˆæª¢æŸ¥æ˜¯å¦æœ‰ç›´æ¥ä½¿ç”¨ OpenAI SDK çš„æƒ…æ³

### å…¶ä»–æˆåŠŸé—œéµå› ç´ 
1. **ç³»çµ±æ€§æ–¹æ³•**: ä¸æ€¥æ–¼ä¿®å¾©ï¼Œå…ˆç†è§£å•é¡Œå…¨è²Œ
2. **é©ç•¶çš„å·¥å…·**: ä½¿ç”¨ Serena MCP ç²¾ç¢ºåˆ†æï¼ŒRuff ä¿è­‰å“è³ª
3. **æ¸…æ™°çš„åˆ†å±¤**: ä¸åŒé¡å‹æ¸¬è©¦æœ‰ä¸åŒçš„ Mock ç­–ç•¥
4. **è©³ç´°çš„æ–‡æª”**: è¨˜éŒ„å•é¡Œã€è§£æ±ºæ–¹æ¡ˆå’Œç¶“é©—æ•™è¨“

### é‡åŒ–æˆæœ
- æ•´åˆæ¸¬è©¦: 7.1% â†’ 100% é€šéç‡
- æ•ˆèƒ½æ¸¬è©¦: 0% â†’ 100% æˆåŠŸç‡ï¼ˆä½†èŠ±è²»å¤§é‡æ™‚é–“åœ¨ LLM Factory å•é¡Œä¸Šï¼‰
- ç¸½ä¿®å¾©æ™‚é–“: ç´„ 8 å°æ™‚ï¼ˆå…¶ä¸­ç´„ 2 å°æ™‚è™•ç† LLM Factory é•è¦ï¼‰
- æŠ€è¡“å‚µå‹™: å¤§å¹…é™ä½

### é é˜²æªæ–½
ç‚ºé¿å…æœªä¾†å†æ¬¡ç™¼ç”Ÿé¡ä¼¼å•é¡Œï¼š
1. **CLAUDE.local.md å·²æ›´æ–°**ï¼šå°‡ LLM Factory è¦å‰‡ç½®æ–¼æœ€é¡¯è‘—ä½ç½®
2. **æ¸¬è©¦æ–‡æª”å·²å¼·åŒ–**ï¼šæ˜ç¢ºè¨˜éŒ„ Claude Code çš„å¸¸è¦‹éŒ¯èª¤æ¨¡å¼
3. **è¨ºæ–·æ¸…å–®å·²å®Œå–„**ï¼šå°‡ LLM Factory æª¢æŸ¥åˆ—ç‚ºç¬¬ä¸€å„ªå…ˆ

é€™äº›ç¶“é©—å°‡å¹«åŠ©åœ˜éšŠåœ¨æœªä¾†æ›´æœ‰æ•ˆåœ°è™•ç†é¡ä¼¼çš„æ¸¬è©¦æŒ‘æˆ°ï¼Œç‰¹åˆ¥æ˜¯èˆ‡ Claude Code å”ä½œæ™‚ã€‚

---

## ğŸ—ï¸ ç¬¬å››éƒ¨åˆ†ï¼šV3 ä¸¦è¡Œå„ªåŒ–çš„æ•™è¨“

### 4.1 ä¸¦è¡Œå„ªåŒ–çš„é™åˆ¶

#### é—œéµç™¼ç¾ï¼š99.9% ç“¶é ¸å®šå¾‹
ç•¶å–®ä¸€æ“ä½œï¼ˆGap Analysis LLMï¼‰ä½”æ“š 99.9% åŸ·è¡Œæ™‚é–“æ™‚ï¼Œä»»ä½•æ¶æ§‹å±¤ç´šçš„ä¸¦è¡Œå„ªåŒ–éƒ½ç„¡æ³•ç”¢ç”Ÿé¡¯è‘—æ•ˆæœã€‚

```
å¯¦æ¸¬æ™‚é–“åˆ†é…ï¼š
â”œâ”€ Keywords: 8.9 ms (0.1%)
â”œâ”€ Embeddings: 365 ms (4.0%)
â”œâ”€ Gap Analysis: 9,183 ms (99.9%)  â† ç„¡æ³•å„ªåŒ–çš„ç“¶é ¸
â””â”€ Index Calculation: 8,823 ms (ä¸¦è¡ŒåŸ·è¡Œ)
```

#### æ•™è¨“ç¸½çµ
1. **æ¸¬é‡å…ˆæ–¼å„ªåŒ–**ï¼šå¿…é ˆå…ˆæº–ç¢ºæ¸¬é‡æ™‚é–“åˆ†é…
2. **è­˜åˆ¥çœŸæ­£ç“¶é ¸**ï¼šä¸æ˜¯æ‰€æœ‰æ…¢éƒ½èƒ½ç”¨ä¸¦è¡Œè§£æ±º
3. **è€ƒæ…®æº–ç¢ºæ€§æˆæœ¬**ï¼šV3 ç‚ºé€Ÿåº¦çŠ§ç‰²æº–ç¢ºæ€§æ˜¯éŒ¯èª¤æ±ºç­–

### 4.2 Cache æ•ˆæ‡‰çš„æ„å¤–ç™¼ç¾

#### Keywords Matching çš„ 65 å€åŠ é€Ÿ
```python
# é¦–æ¬¡åŸ·è¡Œï¼š138ms
keywords = await extract_keywords(job_description)

# å¾ŒçºŒåŸ·è¡Œï¼š2ms (65å€æå‡ï¼)
keywords = await extract_keywords(job_description)  # å‘½ä¸­å¿«å–
```

#### å•Ÿç¤º
- ç°¡å–®çš„è¨˜æ†¶é«”å¿«å–å¯èƒ½æ¯”è¤‡é›œçš„ä¸¦è¡Œæ¶æ§‹æ›´æœ‰æ•ˆ
- æ‡‰è©²å„ªå…ˆè€ƒæ…®å¿«å–å¸¸è¦‹æ“ä½œ

---

## ğŸ¯ ç¬¬äº”éƒ¨åˆ†ï¼šV4 æº–ç¢ºæ€§å„ªå…ˆçš„æ™ºæ…§

### 5.1 æº–ç¢ºæ€§ vs é€Ÿåº¦çš„æ¬Šè¡¡

#### é—œéµæ±ºç­–ï¼šçŠ§ç‰² 1 ç§’æ›å–æº–ç¢ºè©•ä¼°
```python
# V3: å¿«ä½†ä¸æº–ç¢º
gap_result = await gap_analysis(similarity_score=0)  # å‡çš„ï¼

# V4: æ…¢ä½†æº–ç¢º
index_result = await calculate_index()
gap_result = await gap_analysis(
    similarity_score=index_result['similarity_percentage']  # çœŸå¯¦ï¼
)
```

#### å•†æ¥­åƒ¹å€¼è€ƒé‡
- **ç”¨æˆ¶ä¿¡ä»»** > å¿« 1 ç§’
- **éŒ¯èª¤çš„å»ºè­°**æœƒæå®³å“ç‰Œåƒ¹å€¼
- **æº–ç¢ºçš„è©•ä¼°**æå‡ç”¨æˆ¶é»æ€§

### 5.2 ç›¸ä¼¼åº¦é–€æª»çš„ç²¾ç´°è¨­è¨ˆ

#### 6 ç´šåŒ¹é…ç³»çµ±çš„é‚è¼¯
| ç›¸ä¼¼åº¦ | è¨­è¨ˆç†ç”± |
|--------|----------|
| 80%+ | å¹¾ä¹ç†æƒ³ï¼Œåªéœ€å¾®èª¿ |
| 70-79% | æœ‰ç«¶çˆ­åŠ›ï¼Œéœ€é‡å°æ€§æ”¹é€² |
| 60-70% | ç›¸é—œç¶“é©—ï¼Œéœ€è¦æå‡ |
| 50-60% | æœ‰åŸºç¤ï¼Œéœ€è¦å­¸ç¿’ |
| 40-50% | åŸºç¤è–„å¼±ï¼Œéœ€ç³»çµ±å­¸ç¿’ |
| <40% | é ˜åŸŸå·®ç•°å¤§ï¼Œè€ƒæ…®è½‰å‘ |

---

## ğŸ’¡ ç¬¬å…­éƒ¨åˆ†ï¼šç¶œåˆç¶“é©—ç¸½çµ

### 6.1 æŠ€è¡“æ±ºç­–åŸå‰‡

1. **æ¸¬é‡é©…å‹•æ±ºç­–**
   - æ°¸é å…ˆæ¸¬é‡ï¼Œå†å„ªåŒ–
   - ç”¨æ•¸æ“šèªªè©±ï¼Œä¸é çŒœæ¸¬

2. **æº–ç¢ºæ€§å„ªå…ˆ**
   - å¯§å¯æ…¢ä¸€é»ï¼Œä¹Ÿè¦æº–ç¢º
   - ç”¨æˆ¶ä¿¡ä»»æ˜¯æœ€é‡è¦çš„è³‡ç”¢

3. **æ¼¸é€²å¼æ”¹é€²**
   - å¾ 34 å€‹æ¸¬è©¦åˆ° 67 å€‹æ¸¬è©¦
   - æ¯æ¬¡è¿­ä»£éƒ½è¦æœ‰æ¸¬è©¦ä¿è­·

4. **æ¶æ§‹ç°¡æ½”æ€§**
   - ç°¡å–®çš„é †åºåŸ·è¡Œå¯èƒ½æ¯”è¤‡é›œçš„ä¸¦è¡Œæ›´å¥½
   - å¯ç¶­è­·æ€§æ¯”å¾®å°çš„æ€§èƒ½æå‡æ›´é‡è¦

### 6.2 é …ç›®ç®¡ç†ç¶“é©—

1. **æ–‡æª”å…ˆè¡Œ**
   - å®Œæ•´çš„è¦åŠƒæ–‡æª”å¹«åŠ©æ€è€ƒ
   - ä½†ä¸è¦éåº¦è¨­è¨ˆ

2. **å¿«é€Ÿå¯¦é©—**
   - V3 é›–ç„¶å¤±æ•—ï¼Œä½†æä¾›äº†å¯¶è²´æ•¸æ“š
   - å¤±æ•—çš„å¯¦é©—ä¹Ÿæ˜¯é€²æ­¥

3. **åœ˜éšŠæºé€š**
   - æº–ç¢ºæ€§ vs é€Ÿåº¦éœ€è¦æ¥­å‹™åœ˜éšŠåƒèˆ‡æ±ºç­–
   - æŠ€è¡“æ±ºç­–è¦è€ƒæ…®å•†æ¥­åƒ¹å€¼

### 6.3 æœªä¾†å»ºè­°

1. **æ¨¡å‹å±¤å„ªåŒ–**
   - è€ƒæ…® GPT-4.1-mini é™ä½å»¶é²
   - æ¢ç´¢ Streaming Response

2. **æ¥­å‹™å±¤å„ªåŒ–**
   - æ™ºèƒ½å¿«å–å¸¸è¦‹ JD
   - é è¨ˆç®—ç†±é–€è·ä½

3. **æ¶æ§‹å±¤å„ªåŒ–**
   - ä¿æŒç°¡å–®ï¼Œé¿å…éåº¦å·¥ç¨‹
   - é—œæ³¨çœŸæ­£çš„ç“¶é ¸

---

**æ–‡æª”ç‹€æ…‹**: âœ… å®Œæˆ  
**æœ€å¾Œæ›´æ–°**: 2025-08-16  
**ä¸‹ä¸€æ­¥**: å°‡é€™äº›ç¶“é©—æ‡‰ç”¨åˆ°å…¶ä»– API çš„æ¸¬è©¦å¯¦ä½œä¸­