"""
Course Vector Search Service
ä½¿ç”¨ pgvector é€²è¡Œç›¸ä¼¼èª²ç¨‹æœå°‹
"""
import asyncio
import json
import logging
from datetime import datetime
from typing import TYPE_CHECKING, Any

import asyncpg
from pgvector.asyncpg import register_vector

from src.core.monitoring_service import monitoring_service
from src.services.embedding_client import get_course_embedding_client

# Conditional import for course batch functionality
if TYPE_CHECKING:
    from src.models.course_batch_simple import (
        CourseDetailsBatchRequest,
        CourseDetailsBatchResponse,
    )

logger = logging.getLogger(__name__)


class CourseSearchService:
    """èª²ç¨‹å‘é‡æœå°‹æœå‹™"""

    def __init__(self):
        self.embedding_client = None
        self._conn_info = None
        self._connection_pool = None

    async def initialize(self):
        """åˆå§‹åŒ–æœå‹™"""
        import logging
        import os

        logger = logging.getLogger(__name__)

        if not self.embedding_client:
            self.embedding_client = get_course_embedding_client()

        # è¼‰å…¥è³‡æ–™åº«é€£ç·šè³‡è¨Š
        if not self._conn_info:
            # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–
            if all(os.getenv(k) for k in ['POSTGRES_HOST', 'POSTGRES_DATABASE', 'POSTGRES_USER', 'POSTGRES_PASSWORD']):
                self._conn_info = {
                    'host': os.getenv('POSTGRES_HOST'),
                    'database': os.getenv('POSTGRES_DATABASE'),
                    'user': os.getenv('POSTGRES_USER'),
                    'password': os.getenv('POSTGRES_PASSWORD')
                }
                logger.info("âœ… [CourseSearch] Database config loaded from environment variables")
            else:
                # å˜—è©¦å¾æª”æ¡ˆè®€å– (ç”¨æ–¼æœ¬åœ°é–‹ç™¼)
                try:
                    # å„ªå…ˆä½¿ç”¨ tools ç›®éŒ„çš„é…ç½®
                    with open('tools/coursera_db_manager/config/postgres_connection.json') as f:
                        self._conn_info = json.load(f)
                        logger.info("âœ… [CourseSearch] Database config loaded from tools/coursera_db_manager/config/")
                except FileNotFoundError:
                    try:
                        # å‚™ç”¨è·¯å¾‘
                        with open('temp/postgres_connection.json') as f:
                            self._conn_info = json.load(f)
                            logger.info("âœ… [CourseSearch] Database config loaded from temp/")
                    except FileNotFoundError as e:
                        logger.error("âŒ [CourseSearch] No database configuration found (neither env vars nor files)")
                        msg = "Database configuration not found. Please set POSTGRES_* environment variables"
                        raise ValueError(msg) from e

        # å»ºç«‹é€£ç·šæ± 
        if not self._connection_pool:
            import logging
            import time

            from pgvector.asyncpg import register_vector

            logger = logging.getLogger(__name__)
            start_time = time.time()
            logger.info("ğŸ”§ [CourseSearch] Creating connection pool with pgvector registration...")

            # å®šç¾©é€£æ¥åˆå§‹åŒ–å‡½æ•¸
            async def init_connection(conn):
                """åˆå§‹åŒ–æ¯å€‹é€£æ¥: è¨»å†Š pgvector é¡å‹"""
                await register_vector(conn)
                logger.debug(f"âœ… [CourseSearch] Registered pgvector for connection {id(conn)}")

            # å»ºç«‹é€£ç·šæ± , æ¯å€‹é€£æ¥å‰µå»ºæ™‚è‡ªå‹•è¨»å†Š pgvector
            self._connection_pool = await asyncpg.create_pool(
                host=self._conn_info['host'],
                database=self._conn_info['database'],
                user=self._conn_info['user'],
                password=self._conn_info['password'],
                ssl='require',
                min_size=2,  # Increased for better concurrency
                max_size=20,  # Support up to 20 parallel queries
                command_timeout=30,
                init=init_connection  # ğŸš€ é€£æ¥åˆå§‹åŒ–æ™‚è‡ªå‹•è¨»å†Š pgvector
            )
            elapsed = (time.time() - start_time) * 1000
            logger.info(
                f"âœ… [CourseSearch] Connection pool created with pgvector "
                f"pre-registered in {elapsed:.1f}ms, ID: {id(self._connection_pool)}"
            )

    async def search_courses(
        self,
        query: str,
        limit: int = 10,
        similarity_threshold: float = 0.3,
        filters: dict[str, Any] | None = None
    ) -> list[dict[str, Any]]:
        """
        æœå°‹ç›¸ä¼¼èª²ç¨‹

        Args:
            query: æœå°‹æŸ¥è©¢æ–‡å­—
            limit: å›å‚³çµæœæ•¸é‡ä¸Šé™
            similarity_threshold: ç›¸ä¼¼åº¦é–€æª» (0-1)
            filters: é¡å¤–éæ¿¾æ¢ä»¶ (ä¾‹å¦‚: {"manufacturer": "Google"})

        Returns:
            ç›¸ä¼¼èª²ç¨‹åˆ—è¡¨, åŒ…å«ç›¸ä¼¼åº¦åˆ†æ•¸
        """
        start_time = datetime.now()

        try:
            # åˆå§‹åŒ–
            await self.initialize()

            # ç”¢ç”ŸæŸ¥è©¢ embedding
            logger.debug(f"[CourseSearch] Generating embedding for query: {query[:50]}...")
            query_embeddings = await self.embedding_client.create_embeddings([query])

            if not query_embeddings or len(query_embeddings) == 0:
                logger.error("[CourseSearch] Failed to generate query embedding")
                return []

            query_embedding = query_embeddings[0]

            # å¾é€£ç·šæ± å–å¾—é€£ç·š
            async with self._connection_pool.acquire() as conn:
                # è¨»å†Š vector é¡å‹
                await register_vector(conn)
                # å»ºç«‹åŸºæœ¬æŸ¥è©¢
                base_query = """
                    SELECT
                        c.id,
                        c.name,
                        c.description,
                        COALESCE(c.provider_standardized, c.provider) as provider,
                        c.provider_standardized,
                        c.provider_logo_url,
                        c.price as current_price,
                        c.currency,
                        c.image_url,
                        c.affiliate_url,
                        c.course_type_standard as course_type,
                        1 - (c.embedding <=> $1::vector) as similarity
                    FROM courses c
                    WHERE c.platform = 'coursera'
                    AND c.embedding IS NOT NULL
                    AND 1 - (c.embedding <=> $1::vector) >= $2
                """

                params = [query_embedding, similarity_threshold]

                # åŠ å…¥é¡å¤–éæ¿¾æ¢ä»¶
                if filters:
                    filter_conditions = []
                    param_index = 3

                    if 'provider' in filters:
                        filter_conditions.append(f"COALESCE(c.provider_standardized, c.provider) = ${param_index}")
                        params.append(filters['provider'])
                        param_index += 1

                    if 'max_price' in filters:
                        filter_conditions.append(f"c.current_price <= ${param_index}")
                        params.append(filters['max_price'])
                        param_index += 1

                    if 'category' in filters:
                        filter_conditions.append(f"c.category = ${param_index}")
                        params.append(filters['category'])
                        param_index += 1

                    # æ”¯æ´ category_list éæ¿¾ (å¤šå€‹åˆ†é¡)
                    if 'category_list' in filters:
                        placeholders = ','.join([f'${param_index + i}' for i in range(len(filters['category_list']))])
                        filter_conditions.append(f"c.category IN ({placeholders})")
                        params.extend(filters['category_list'])
                        param_index += len(filters['category_list'])

                    if filter_conditions:
                        base_query += " AND " + " AND ".join(filter_conditions)

                # åŠ å…¥æ’åºå’Œé™åˆ¶
                base_query += f"""
                    ORDER BY similarity DESC
                    LIMIT ${len(params) + 1}
                """
                params.append(limit)

                # åŸ·è¡ŒæŸ¥è©¢
                logger.debug(
                    f"[CourseSearch] Executing vector search with threshold={similarity_threshold}, "
                    f"limit={limit}"
                )
                results = await conn.fetch(base_query, *params)

                # æ ¼å¼åŒ–çµæœ
                courses = []
                for row in results:
                    course = {
                        "id": row['id'],
                        "name": row['name'],
                        "description": (
                            row['description'][:500] + "..."
                            if len(row['description']) > 500 else row['description']
                        ),
                        "provider": row['provider'],
                        "provider_standardized": row['provider_standardized'] or '',
                        "provider_logo_url": row['provider_logo_url'] or '',
                        "price": float(row['current_price']),
                        "currency": row['currency'],
                        "image_url": row['image_url'],
                        "affiliate_url": row.get('affiliate_url') or '',
                        "course_type": row.get('course_type', 'course'),
                        "similarity_score": round(float(row['similarity']), 4)
                    }
                    courses.append(course)

                duration = (datetime.now() - start_time).total_seconds()

                # è¨˜éŒ„ç›£æ§è³‡è¨Š
                monitoring_service.track_event("CourseSearchCompleted", {
                    "query": query[:100],
                    "results_count": len(courses),
                    "duration_seconds": duration,
                    "similarity_threshold": similarity_threshold,
                    "has_filters": bool(filters)
                })

                logger.info(f"[CourseSearch] Found {len(courses)} courses in {duration:.2f}s")

                return courses

        except Exception as e:
            logger.error(f"[CourseSearch] Error: {e}")
            monitoring_service.track_event("CourseSearchError", {
                "query": query[:100],
                "error": str(e)
            })
            raise

    async def find_similar_courses(
        self,
        course_id: str,
        limit: int = 5
    ) -> list[dict[str, Any]]:
        """
        æ‰¾å‡ºèˆ‡æŒ‡å®šèª²ç¨‹ç›¸ä¼¼çš„å…¶ä»–èª²ç¨‹

        Args:
            course_id: èª²ç¨‹ ID
            limit: å›å‚³çµæœæ•¸é‡ä¸Šé™

        Returns:
            ç›¸ä¼¼èª²ç¨‹åˆ—è¡¨
        """
        await self.initialize()

        # å»ºç«‹è³‡æ–™åº«é€£ç·š
        conn = await asyncpg.connect(
            host=self._conn_info['host'],
            database=self._conn_info['database'],
            user=self._conn_info['user'],
            password=self._conn_info['password'],
            ssl='require'
        )

        # è¨»å†Š vector é¡å‹
        await register_vector(conn)

        try:
            # å–å¾—ç›®æ¨™èª²ç¨‹çš„ embedding
            target_embedding = await conn.fetchval("""
                SELECT embedding
                FROM courses
                WHERE id = $1
            """, course_id)

            if target_embedding is None:
                return []

            # æœå°‹ç›¸ä¼¼èª²ç¨‹ (æ’é™¤è‡ªå·±)
            results = await conn.fetch("""
                SELECT
                    c.id,
                    c.name,
                    c.description,
                    COALESCE(c.provider_standardized, c.provider) as provider,
                    c.provider_standardized,
                    c.provider_logo_url,
                    c.price as current_price,
                    c.currency,
                    c.image_url,
                    c.affiliate_url,
                    c.course_type,
                    1 - (c.embedding <=> $1::vector) as similarity
                FROM courses c
                WHERE c.id != $2
                AND c.platform = 'coursera'
                AND c.embedding IS NOT NULL
                ORDER BY c.embedding <=> $1::vector
                LIMIT $3
            """, target_embedding, course_id, limit)

            # ä¸å†éœ€è¦æ˜ å°„, ç›´æ¥ä½¿ç”¨ course_type_standard

            # æ ¼å¼åŒ–çµæœ
            similar_courses = []
            for row in results:
                # ç›´æ¥ä½¿ç”¨ course_type_standard
                course_type = row.get('course_type', 'course')

                # å°‡ similarity è½‰æ›ç‚ºæ•´æ•¸ç™¾åˆ†æ¯”
                similarity_percentage = int(float(row['similarity']) * 100)

                course = {
                    "id": row['id'],
                    "name": row['name'],
                    "description": (
                        row['description'][:300] + "..."
                        if len(row['description']) > 300 else row['description']
                    ),
                    "provider": row['provider'],
                    "provider_standardized": row['provider_standardized'] or '',
                    "provider_logo_url": row['provider_logo_url'] or '',
                    "price": float(row['current_price']),
                    "currency": row.get('currency', 'USD'),
                    "image_url": row['image_url'],
                    "affiliate_url": row.get('affiliate_url', ''),
                    "course_type": course_type,
                    "similarity_score": similarity_percentage
                }
                similar_courses.append(course)

            return similar_courses

        finally:
            await conn.close()

    async def get_popular_categories(self) -> list[dict[str, Any]]:
        """å–å¾—ç†±é–€èª²ç¨‹åˆ†é¡"""
        await self.initialize()

        conn = await asyncpg.connect(
            host=self._conn_info['host'],
            database=self._conn_info['database'],
            user=self._conn_info['user'],
            password=self._conn_info['password'],
            ssl='require'
        )

        try:
            results = await conn.fetch("""
                SELECT
                    category,
                    COUNT(*) as course_count
                FROM courses
                WHERE platform = 'coursera'
                AND category IS NOT NULL
                AND category != ''
                GROUP BY category
                ORDER BY course_count DESC
                LIMIT 20
            """)

            categories = [
                {
                    "name": row['category'],
                    "course_count": row['course_count']
                }
                for row in results
            ]

            return categories

        finally:
            await conn.close()

    async def search_courses_v2(
        self,
        skill_name: str,
        search_context: str = "",
        limit: int = 5,
        similarity_threshold: float = 0.3
    ) -> dict[str, Any]:
        """
        æ”¹é€²ç‰ˆèª²ç¨‹æœå°‹ (ç¬¬äºŒç‰ˆ)

        Args:
            skill_name: æŠ€èƒ½åç¨±
            search_context: æœå°‹æƒ…å¢ƒæè¿°
            limit: å›å‚³çµæœæ•¸é‡ (é è¨­ 5, æœ€å¤§ 10)
            similarity_threshold: ç›¸ä¼¼åº¦é–€æª» (é è¨­ 0.3)

        Returns:
            CourseSearchResponse æ ¼å¼çš„å­—å…¸
        """
        from src.models.course_search import (
            CourseResult,
            CourseSearchData,
            CourseSearchResponse,
            CourseTypeCount,
            ErrorModel,
        )
        from src.services.course_cache import CourseSearchCache

        start_time = datetime.now()

        # åˆå§‹åŒ–å¿«å–
        if not hasattr(self, 'cache'):
            self.cache = CourseSearchCache()

        # å»ºç«‹å¿«å–éµå€¼
        cache_key = self.cache.get_cache_key(
            skill_name, search_context, "", similarity_threshold
        )

        # æª¢æŸ¥å¿«å–
        cached_result = self.cache.get(cache_key)
        if cached_result:
            monitoring_service.track_event("CourseSearchCacheHit", {
                "skill_name": skill_name,
                "cache_key": cache_key
            })
            return CourseSearchResponse(**cached_result)

        try:
            # å»ºç«‹æŸ¥è©¢æ–‡æœ¬
            query_text = f"{skill_name} {search_context}".strip()

            # å‘é‡æœå°‹ (å«é‡è©¦)
            courses = await self._search_with_retry(
                query_text=query_text,
                limit=limit,
                threshold=similarity_threshold
            )

            # å»ºç«‹å›æ‡‰
            duration_ms = int((datetime.now() - start_time).total_seconds() * 1000)

            # æ ¼å¼åŒ–èª²ç¨‹çµæœä¸¦çµ±è¨ˆé¡å‹
            course_results = []
            type_counts = {
                'course': 0,
                'certification': 0,
                'specialization': 0,
                'degree': 0,
                'project': 0
            }

            for course in courses:
                # å°‡ similarity_score è½‰æ›ç‚ºæ•´æ•¸ç™¾åˆ†æ¯”
                similarity_percentage = int(float(course.get('similarity_score', 0)) * 100)

                # å–å¾—èª²ç¨‹é¡å‹
                course_type = course.get('course_type', 'course')

                # çµ±è¨ˆèª²ç¨‹é¡å‹ (ç›´æ¥ä½¿ç”¨ course_type_standard çš„å€¼)
                if course_type in type_counts:
                    type_counts[course_type] += 1

                course_result = CourseResult(
                    id=course['id'],
                    name=course['name'],
                    description=course['description'][:500] + "..."
                               if len(course.get('description', '')) > 500
                               else course.get('description', ''),
                    provider=course.get('provider', ''),
                    provider_standardized=course.get('provider_standardized', ''),
                    provider_logo_url=course.get('provider_logo_url', ''),
                    price=float(course.get('price', 0)),
                    currency=course.get('currency', 'USD'),
                    image_url=course.get('image_url', ''),
                    affiliate_url=course.get('affiliate_url', ''),
                    course_type=course_type,
                    similarity_score=similarity_percentage
                )
                course_results.append(course_result)

            response = CourseSearchResponse(
                success=True,
                data=CourseSearchData(
                    results=course_results,
                    total_count=len(course_results),
                    returned_count=len(course_results),
                    query=query_text,
                    search_time_ms=duration_ms,
                    filters_applied={
                        "similarity_threshold": similarity_threshold
                    },
                    type_counts=CourseTypeCount(**type_counts)
                ),
                error=ErrorModel()
            )

            # å­˜å…¥å¿«å–
            self.cache.set(cache_key, response.model_dump())

            # è¨˜éŒ„ç›£æ§
            self._track_search_success(skill_name, search_context, courses, duration_ms)

            return response

        except Exception as e:
            # è¨˜éŒ„éŒ¯èª¤
            self._track_search_error(e, skill_name, search_context)

            # å›å‚³éŒ¯èª¤ (Bubble.io ç›¸å®¹)
            return CourseSearchResponse(
                success=False,
                data=CourseSearchData(),
                error=ErrorModel(
                    code=self._get_error_code(e),
                    message="Search failed",
                    details=str(e)
                )
            )

    async def _search_with_retry(
        self,
        query_text: str,
        limit: int,
        threshold: float,
        max_retries: int = 3
    ) -> list[dict]:
        """å«é‡è©¦æ©Ÿåˆ¶çš„æœå°‹"""
        retry_delays = [1.0, 2.0, 4.0]

        for attempt in range(max_retries):
            try:
                # åˆå§‹åŒ–æœå‹™
                await self.initialize()

                # ç”¢ç”Ÿ embedding
                logger.debug(f"[CourseSearch] Generating embedding for: {query_text[:50]}...")
                embeddings = await self.embedding_client.create_embeddings([query_text])

                if not embeddings or len(embeddings) == 0:
                    raise Exception("Failed to generate embeddings")

                query_embedding = embeddings[0]

                # åŸ·è¡Œå‘é‡æœå°‹
                courses = await self._execute_vector_search_v2(
                    embedding=query_embedding,
                    filters={},
                    limit=limit,
                    threshold=threshold
                )

                return courses

            except Exception as e:
                logger.warning(f"[CourseSearch] Attempt {attempt + 1} failed: {e}")

                if attempt == max_retries - 1:
                    raise Exception(f"Search failed after {max_retries} attempts: {e!s}") from e

                await asyncio.sleep(retry_delays[attempt])

    async def _execute_vector_search_v2(
        self,
        embedding: list[float],
        filters: dict[str, Any],
        limit: int,
        threshold: float
    ) -> list[dict[str, Any]]:
        """åŸ·è¡Œå‘é‡æœå°‹ (ç¬¬äºŒç‰ˆ)"""
        # å¾é€£ç·šæ± å–å¾—é€£ç·š
        async with self._connection_pool.acquire() as conn:
            # è¨»å†Š vector é¡å‹
            await register_vector(conn)
            # å»ºç«‹åŸºæœ¬æŸ¥è©¢
            base_query = """
                SELECT
                    c.id,
                    c.name,
                    c.description,
                    COALESCE(c.provider_standardized, c.provider) as provider,
                    c.provider_standardized,
                    c.provider_logo_url,
                    c.price as current_price,
                    c.currency,
                    c.image_url,
                    c.affiliate_url as tracking_url,
                    c.course_type_standard as course_type,
                    1 - (c.embedding <=> $1::vector) as similarity_score
                FROM courses c
                WHERE c.platform = 'coursera'
                AND c.embedding IS NOT NULL
                AND 1 - (c.embedding <=> $1::vector) >= $2
            """

            params = [embedding, threshold]

            # åŠ å…¥åˆ†é¡éæ¿¾
            if 'category_list' in filters:
                placeholders = ','.join([f'${i+3}' for i in range(len(filters['category_list']))])
                base_query += f" AND c.category IN ({placeholders})"
                params.extend(filters['category_list'])

            # åŠ å…¥æ’åºå’Œé™åˆ¶
            base_query += f"""
                ORDER BY c.embedding <=> $1::vector
                LIMIT ${len(params) + 1}
            """
            params.append(limit)

            # åŸ·è¡ŒæŸ¥è©¢
            logger.debug(f"[CourseSearch] Executing vector search with threshold={threshold}, limit={limit}")
            results = await conn.fetch(base_query, *params)

            # ä¸å†éœ€è¦æ˜ å°„, ç›´æ¥ä½¿ç”¨ course_type_standard

            # æ ¼å¼åŒ–çµæœ
            courses = []
            for row in results:
                # ç›´æ¥ä½¿ç”¨ course_type_standard
                course_type = row.get('course_type', 'course')

                course = {
                    "id": row['id'],
                    "name": row['name'],
                    "description": row['description'],
                    "provider": row['provider'],
                    "provider_standardized": row['provider_standardized'] or '',
                    "provider_logo_url": row['provider_logo_url'] or '',
                    "price": float(row['current_price']),
                    "currency": row['currency'],
                    "image_url": row['image_url'],
                    "affiliate_url": row['tracking_url'] or '',
                    "course_type": course_type,
                    "similarity_score": float(row['similarity_score'])
                }
                courses.append(course)

            logger.info(f"[CourseSearch] Found {len(courses)} courses")
            return courses

    def _track_search_success(self, skill_name: str, search_context: str,
                             courses: list, duration_ms: int):
        """è¨˜éŒ„æˆåŠŸçš„æœå°‹"""
        course_ids = [c['id'] for c in courses[:5]]
        similarity_scores = [c.get('similarity_score', 0) for c in courses[:5]]

        monitoring_service.track_event("CourseSearchExecuted", {
            "skill_name": skill_name,
            "search_context": search_context,
            "result_count": len(courses),
            "course_ids": course_ids,
            "similarity_scores": similarity_scores,
            "search_duration_ms": duration_ms,
            "success": True
        })

    def _track_search_error(self, error: Exception, skill_name: str,
                           search_context: str):
        """è¨˜éŒ„æœå°‹éŒ¯èª¤"""
        monitoring_service.track_event("CourseSearchError", {
            "error_code": self._get_error_code(error),
            "error_type": type(error).__name__,
            "error_message": str(error),
            "skill_name": skill_name,
            "search_context": search_context
        })

    def _get_error_code(self, error: Exception) -> str:
        """å–å¾—éŒ¯èª¤ä»£ç¢¼"""
        error_type = type(error).__name__

        if "embedding" in str(error).lower():
            return "EMBEDDING_GENERATION_FAILED"
        elif "connection" in str(error).lower():
            return "DATABASE_CONNECTION_ERROR"
        elif "timeout" in str(error).lower():
            return "QUERY_TIMEOUT"
        else:
            return f"UNKNOWN_ERROR_{error_type.upper()}"

    def format_description_to_html(self, description: str) -> str:
        """
        å°‡èª²ç¨‹æè¿°è½‰æ›ç‚º HTML æ ¼å¼, ä¾› Bubble.io HTML å…ƒä»¶ç›´æ¥é¡¯ç¤º

        è™•ç†é …ç›®:
        1. HTML ç‰¹æ®Šå­—å…ƒè½‰ç¾© (å¿…é ˆ)
        2. æ›è¡Œç¬¦è™Ÿè™•ç† (å¿…é ˆ)
        3. URL è‡ªå‹•è½‰é€£çµ (å»ºè­°)
        4. Markdown ç²—é«”/æ–œé«” (å»ºè­°)
        5. Bullet points (å»ºè­°)

        Args:
            description: åŸå§‹èª²ç¨‹æè¿°æ–‡å­—

        Returns:
            HTML æ ¼å¼åŒ–çš„æè¿°
        """
        import html
        import re

        if not description:
            return ""

        # 0. å…ˆè™•ç†å­—é¢å­—ç¬¦ä¸²çš„ \n (å¾è³‡æ–™åº«è®€å–çš„)
        # è³‡æ–™åº«ä¸­å„²å­˜çš„æ˜¯å…©å€‹å­—å…ƒ: åæ–œç·šå’Œn, ä¸æ˜¯çœŸæ­£çš„æ›è¡Œç¬¦
        description = description.replace('\\n', '\n')


        # 1. HTML ç‰¹æ®Šå­—å…ƒè½‰ç¾© (æœ€é‡è¦, é˜²æ­¢ç ´å£ HTML çµæ§‹)
        description = html.escape(description)

        # 2. è™•ç† Markdown ç²—é«” **text** â†’ <strong>text</strong>
        # ä½¿ç”¨ <strong> è€Œé <b> æ›´ç¬¦åˆèªç¾©åŒ– HTML
        description = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', description)

        # 3. è™•ç† Markdown æ–œé«” *text* â†’ <em>text</em>
        # é¿å…èˆ‡åˆ†éš”ç·šè¡çª, ç¢ºä¿å‰å¾Œéƒ½ä¸æ˜¯ *
        description = re.sub(r'(?<!\*)\*([^*\n]+)\*(?!\*)', r'<em>\1</em>', description)

        # 4. è™•ç† URL è‡ªå‹•è½‰æ›ç‚ºå¯é»æ“Šé€£çµ
        # ä½¿ç”¨ target="_blank" åœ¨æ–°è¦–çª—é–‹å•Ÿ, rel="noopener" æé«˜å®‰å…¨æ€§
        description = re.sub(
            r'(https?://[^\s<>)"\']+)',
            r'<a href="\1" target="_blank" rel="noopener noreferrer">\1</a>',
            description
        )

        # 5. è™•ç†æ®µè½å’Œæ›è¡Œ
        # å…ˆåˆ†å‰²æˆæ®µè½ (é€£çºŒå…©å€‹æ›è¡Œ)
        paragraphs = description.split('\n\n')
        formatted_paragraphs = []

        for para in paragraphs:
            if not para.strip():
                continue

            # æª¢æŸ¥æ˜¯å¦åŒ…å« bullet points
            lines = para.split('\n')
            has_bullets = any(line.strip().startswith(('â€¢', 'â—', 'â– ', 'â–ª')) for line in lines)

            if has_bullets:
                # è™•ç† bullet list
                list_items = []
                non_list_content = []

                for line in lines:
                    line = line.strip()
                    if not line:
                        continue

                    # æª¢æŸ¥æ˜¯å¦æ˜¯ bullet point
                    is_bullet = False
                    for bullet in ['â€¢', 'â—', 'â– ', 'â–ª']:
                        if line.startswith(bullet):
                            # ç§»é™¤ bullet ç¬¦è™Ÿä¸¦åŠ å…¥åˆ—è¡¨
                            content = line[len(bullet):].strip()
                            list_items.append(f'<li>{content}</li>')
                            is_bullet = True
                            break

                    # æª¢æŸ¥ - æˆ– * ä½œç‚º bullet (éœ€è¦å¾Œé¢æœ‰ç©ºæ ¼)
                    if not is_bullet and len(line) > 2 and line[0] in ['-', '*'] and line[1] == ' ':
                        content = line[2:].strip()
                        list_items.append(f'<li>{content}</li>')
                        is_bullet = True

                    if not is_bullet and not list_items:
                        # é‚„æ²’é–‹å§‹åˆ—è¡¨çš„å…§å®¹
                        non_list_content.append(line)

                # çµ„åˆçµæœ
                if non_list_content:
                    # åˆ—è¡¨å‰çš„æ–‡å­—, å–®æ›è¡Œè½‰ç‚º <br>
                    text = '<br>'.join(non_list_content)
                    formatted_paragraphs.append(f'<p>{text}</p>')

                if list_items:
                    # æ·»åŠ ç„¡åºåˆ—è¡¨
                    formatted_paragraphs.append(f'<ul>{"".join(list_items)}</ul>')
            else:
                # æ™®é€šæ®µè½, å°‡å–®æ›è¡Œè½‰ç‚º <br>
                para_html = para.replace('\n', '<br>')
                formatted_paragraphs.append(f'<p>{para_html}</p>')

        # çµ„åˆæ‰€æœ‰æ®µè½
        return ''.join(formatted_paragraphs)

    async def get_courses_by_ids(
        self,
        request: "CourseDetailsBatchRequest"
    ) -> "CourseDetailsBatchResponse":
        """
        æ‰¹æ¬¡æŸ¥è©¢èª²ç¨‹è©³æƒ… by IDs

        Args:
            request: æ‰¹æ¬¡æŸ¥è©¢è«‹æ±‚ç‰©ä»¶

        Returns:
            CourseDetailsBatchResponse: èª²ç¨‹è©³æƒ…å›æ‡‰
        """
        from datetime import datetime

        from src.models.course_batch_simple import CourseDetailsBatchResponse
        from src.services.course_cache import CourseSearchCache

        start_time = datetime.now()
        timeline = []

        def track_time(task: str, description: str, start: datetime) -> dict:
            """è¿½è¹¤ä»»å‹™æ™‚é–“"""
            duration_ms = int((datetime.now() - start).total_seconds() * 1000)
            if request.enable_time_tracking and duration_ms > 50:  # åªè¨˜éŒ„è¶…é 50ms çš„æ“ä½œ
                timeline.append({
                    "task": task,
                    "duration_ms": duration_ms,
                    "description": description
                })
            return {"duration": duration_ms}

        try:
            # 1. æº–å‚™éšæ®µ
            prep_start = datetime.now()

            # è™•ç† max_courses é™åˆ¶
            course_ids = request.course_ids[:request.max_courses] if request.max_courses else request.course_ids
            skipped_count = len(request.course_ids) - len(course_ids)

            track_time("preparation", "Input validation and limits", prep_start)

            # 2. å¿«å–æ“ä½œ
            cache_start = datetime.now()

            # åˆå§‹åŒ–å¿«å–
            if not hasattr(self, 'cache'):
                self.cache = CourseSearchCache()

            # æª¢æŸ¥å¿«å–
            cached_courses = []
            uncached_ids = []

            for course_id in course_ids:
                cache_key = f"course_detail:{course_id}:{request.full_description}:{request.description_max_length}"
                cached = self.cache.get(cache_key)
                if cached:
                    cached_courses.append(cached)
                else:
                    uncached_ids.append(course_id)

            track_time("cache_operations", "Check cached courses", cache_start)

            # 3. è³‡æ–™åº«æ“ä½œ
            db_courses = []
            if uncached_ids:
                db_start = datetime.now()

                # åˆå§‹åŒ–é€£ç·š
                await self.initialize()

                # æ‰¹æ¬¡æŸ¥è©¢
                async with self._connection_pool.acquire() as conn:
                    # ä½¿ç”¨ array_position ä¿æŒé †åº
                    query = """
                        SELECT
                            id,
                            name,
                            description,
                            COALESCE(provider_standardized, provider) as provider,
                            provider_standardized,
                            provider_logo_url,
                            price as current_price,
                            currency,
                            image_url,
                            affiliate_url,
                            course_type_standard as course_type,
                            array_position($1::text[], id) as sort_order
                        FROM courses
                        WHERE id = ANY($1::text[])
                        AND platform = 'coursera'
                        ORDER BY array_position($1::text[], id)
                    """

                    results = await conn.fetch(query, uncached_ids)

                    for row in results:
                        # è™•ç†æè¿°
                        description = row['description'] or ''

                        # æ ¹æ“š format_description_html æ±ºå®šæ˜¯å¦æ ¼å¼åŒ–
                        if request.format_description_html:
                            # HTML æ ¼å¼åŒ–è™•ç†
                            description_field = self.format_description_to_html(description)
                        else:
                            # æ¨™æº–æè¿°è™•ç† (å¯èƒ½æˆªæ–·)
                            if not request.full_description and len(description) > request.description_max_length:
                                description_field = description[:request.description_max_length] + "..."
                            else:
                                description_field = description

                        course = {
                            "id": row['id'],
                            "name": row['name'],
                            "description": description_field,  # å›ºå®šä½¿ç”¨ description æ¬„ä½
                            "provider": row['provider'],
                            "provider_standardized": row['provider_standardized'] or '',
                            "provider_logo_url": row['provider_logo_url'] or '',
                            "price": float(row['current_price'] or 0),
                            "currency": row['currency'] or 'USD',
                            "image_url": row['image_url'] or '',
                            "affiliate_url": row['affiliate_url'] or '',
                            "course_type": row['course_type'] or 'course'
                        }

                        db_courses.append(course)

                        # å¿«å–çµæœ
                        cache_key = (
                            f"course_detail:{row['id']}:"
                            f"{request.full_description}:{request.description_max_length}"
                        )
                        self.cache.set(cache_key, course)

                track_time("db_operations", "Query uncached courses", db_start)

            # 4. è™•ç†èˆ‡çµ„åˆçµæœ
            process_start = datetime.now()

            # åˆä½µçµæœä¸¦ä¿æŒåŸå§‹é †åº
            all_courses = cached_courses + db_courses
            courses_dict = {c['id']: c for c in all_courses}

            # æŒ‰åŸå§‹é †åºæ’åº
            ordered_courses = []
            not_found_ids = []

            for course_id in course_ids:
                if course_id in courses_dict:
                    ordered_courses.append(courses_dict[course_id])
                else:
                    not_found_ids.append(course_id)

            track_time("processing", "Format and build response", process_start)

            # è¨ˆç®—çµ±è¨ˆ
            total_found = len(ordered_courses)
            cache_hit_rate = len(cached_courses) / len(course_ids) if course_ids else 0
            all_not_found = total_found == 0

            # å»ºç«‹æ™‚é–“è¿½è¹¤æ‘˜è¦
            time_tracking = None
            if request.enable_time_tracking:
                total_ms = int((datetime.now() - start_time).total_seconds() * 1000)

                # è¨ˆç®—ç™¾åˆ†æ¯”
                summary = {}
                for item in timeline:
                    key = f"{item['task']}_pct"
                    summary[key] = round((item['duration_ms'] / total_ms) * 100, 1) if total_ms > 0 else 0

                time_tracking = {
                    "enabled": True,
                    "total_ms": total_ms,
                    "timeline": timeline,
                    "summary": summary
                }

            # è¿”å›çµæœ
            return CourseDetailsBatchResponse(
                success=True,
                courses=ordered_courses,
                total_found=total_found,
                requested_count=len(request.course_ids),
                processed_count=len(course_ids),
                skipped_count=skipped_count,
                not_found_ids=not_found_ids,
                cache_hit_rate=round(cache_hit_rate, 2),
                from_cache_count=len(cached_courses),
                all_not_found=all_not_found,
                fallback_url="https://imp.i384100.net/mOkdyq" if all_not_found else None,
                time_tracking=time_tracking,
                error={"code": "", "message": "", "details": ""}
            )

        except Exception as e:
            logger.error(f"[CourseBatch] Error in get_courses_by_ids: {e}")

            # è¿”å›éŒ¯èª¤å›æ‡‰
            return CourseDetailsBatchResponse(
                success=False,
                courses=[],
                total_found=0,
                requested_count=len(request.course_ids),
                processed_count=0,
                skipped_count=0,
                not_found_ids=request.course_ids,
                cache_hit_rate=0.0,
                from_cache_count=0,
                all_not_found=True,
                fallback_url="https://imp.i384100.net/mOkdyq",
                time_tracking=None,
                error={
                    "code": "BATCH_QUERY_ERROR",
                    "message": "Failed to query courses",
                    "details": str(e)
                }
            )
